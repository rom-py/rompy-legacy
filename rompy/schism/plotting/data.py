"""
Data plotting functionality for SCHISM input files.

This module provides comprehensive visualization capabilities for SCHISM input data
including boundary conditions, atmospheric forcing, and tidal data.
"""

import logging
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

import matplotlib.pyplot as plt
import numpy as np
import xarray as xr
from matplotlib.axes import Axes
from matplotlib.figure import Figure
from scipy.spatial import cKDTree

from .core import BasePlotter, PlotConfig, PlotValidator
from .utils import (
    detect_file_type,
    get_variable_info,
    load_schism_data,
    create_time_subset,
    setup_colormap,
    add_boundary_overlay,
    get_geographic_extent,
    create_diverging_colormap_levels
)

logger = logging.getLogger(__name__)


class DataPlotter(BasePlotter):
    """
    SCHISM data plotting functionality.

    This class provides methods for visualizing SCHISM input data files
    including 3D boundary conditions, atmospheric forcing, and tidal data.

    Parameters
    ----------
    config : Optional[Any]
        SCHISM configuration object
    grid_file : Optional[Union[str, Path]]
        Path to grid file if config is not provided
    plot_config : Optional[PlotConfig]
        Plotting configuration parameters
    """

    def __init__(
        self,
        config: Optional[Any] = None,
        grid_file: Optional[Union[str, Path]] = None,
        plot_config: Optional[PlotConfig] = None,
        file_map: Optional[Dict[str, Union[str, Path]]] = None
    ):
        """
        Initialize DataPlotter.

        Parameters
        ----------
        config : Optional[Any]
            SCHISM configuration object
        grid_file : Optional[Union[str, Path]]
            Path to grid file if config is not provided
        plot_config : Optional[PlotConfig]
            Plotting configuration parameters
        file_map : Optional[Dict[str, Union[str, Path]]]
            Mapping of logical data keys to file paths (recommended)
        """
        super().__init__(config, grid_file, plot_config)
        self.file_map = file_map or {}

    def plot(self, data_type: str, **kwargs) -> Tuple[Figure, Axes]:
        """
        Main plotting method using file_map for file discovery.

        Parameters
        ----------
        data_type : str
            Logical key for SCHISM data file (e.g., 'salinity_3d', 'temperature_3d', 'velocity_3d', 'elevation_2d', 'atmospheric', 'bctides', etc.)
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        if data_type not in self.file_map:
            raise ValueError(f"Required file for '{data_type}' not found in file_map.")
        file_path = self.file_map[data_type]
        file_type = detect_file_type(file_path)

        if file_type == 'salinity_3d':
            return self.plot_salinity_3d(**kwargs)
        elif file_type == 'temperature_3d':
            return self.plot_temperature_3d(**kwargs)
        elif file_type == 'velocity_3d':
            return self.plot_velocity_3d(**kwargs)
        elif file_type == 'elevation_2d':
            return self.plot_elevation_2d(**kwargs)
        elif file_type == 'atmospheric':
            return self.plot_atmospheric_spatial(**kwargs)
        elif file_type == 'gr3':
            return self.plot_gr3_file(**kwargs)
        elif file_type == 'bctides':
            return self.plot_bctides_file(**kwargs)
        else:
            return self.plot_boundary_data(**kwargs)

    def plot_boundary_data(
        self,
        file_path: Union[str, Path],
        variable: Optional[str] = None,
        time_idx: int = 0,
        level_idx: int = 0,
        ax: Optional[Axes] = None,
        plot_type: str = "spatial",
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot boundary condition data from SCHISM input files.

        Parameters
        ----------
        file_path : Union[str, Path]
            Path to boundary data file
        variable : Optional[str]
            Variable to plot. If None, first available variable is used.
        time_idx : int, optional
            Time index to plot. Default is 0.
        level_idx : int, optional
            Vertical level index for 3D data. Default is 0 (surface).
        ax : Optional[Axes]
            Existing axes to plot on
        plot_type : str, optional
            Type of plot: 'spatial', 'timeseries', 'profile'. Default is 'spatial'.
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        ds = load_schism_data(file_path)

        # Get variable name
        if variable is None:
            variable = str(list(ds.data_vars)[0])

        PlotValidator.validate_dataset(ds, required_vars=[variable])

        if plot_type == "spatial":
            return self._plot_boundary_spatial(ds, variable, time_idx, level_idx, ax, **kwargs)
        elif plot_type == "timeseries":
            return self._plot_boundary_timeseries(ds, variable, level_idx, ax, **kwargs)
        elif plot_type == "profile":
            return self._plot_boundary_profile(ds, variable, time_idx, ax, **kwargs)
        else:
            raise ValueError(f"Unknown plot type: {plot_type}")

    def plot_salinity_3d(
        self,
        time_idx: int = 0,
        level_idx: int = 0,
        ax: Optional[Axes] = None,
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot 3D salinity boundary data using file_map.

        Parameters
        ----------
        time_idx : int, optional
            Time index to plot. Default is 0.
        level_idx : int, optional
            Vertical level index. Default is 0 (surface).
        ax : Optional[Axes]
            Existing axes to plot on
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        file_path = self.file_map.get("salinity_3d")
        if not file_path:
            raise ValueError("salinity_3d file not found in file_map.")
        return self.plot_boundary_data(
            file_path, variable="salinity", time_idx=time_idx,
            level_idx=level_idx, ax=ax, **kwargs
        )

    def plot_temperature_3d(
        self,
        time_idx: int = 0,
        level_idx: int = 0,
        ax: Optional[Axes] = None,
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot 3D temperature boundary data using file_map.

        Parameters
        ----------
        time_idx : int, optional
            Time index to plot. Default is 0.
        level_idx : int, optional
            Vertical level index. Default is 0 (surface).
        ax : Optional[Axes]
            Existing axes to plot on
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        file_path = self.file_map.get("temperature_3d")
        if not file_path:
            raise ValueError("temperature_3d file not found in file_map.")
        return self.plot_boundary_data(
            file_path, variable="temperature", time_idx=time_idx,
            level_idx=level_idx, ax=ax, **kwargs
        )

    def plot_velocity_3d(
        self,
        time_idx: int = 0,
        level_idx: int = 0,
        ax: Optional[Axes] = None,
        plot_component: str = "magnitude",
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot 3D velocity boundary data using file_map.

        Parameters
        ----------
        time_idx : int, optional
            Time index to plot. Default is 0.
        level_idx : int, optional
            Vertical level index. Default is 0 (surface).
        ax : Optional[Axes]
            Existing axes to plot on
        plot_component : str, optional
            Component to plot: 'magnitude', 'u', 'v', 'vectors'. Default is 'magnitude'.
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        file_path = self.file_map.get("velocity_3d")
        if not file_path:
            raise ValueError("velocity_3d file not found in file_map.")
        ds = load_schism_data(file_path)

        # Find velocity components
        u_var = None
        v_var = None
        for var in ds.data_vars:
            var_str = str(var)
            if 'u' in var_str.lower() and 'velocity' in var_str.lower():
                u_var = var_str
            elif 'v' in var_str.lower() and 'velocity' in var_str.lower():
                v_var = var_str

        if u_var is None or v_var is None:
            # Try common naming conventions
            possible_u = ['u', 'uvel', 'u_velocity', 'eastward_velocity']
            possible_v = ['v', 'vvel', 'v_velocity', 'northward_velocity']

            for u_name in possible_u:
                if u_name in ds.data_vars:
                    u_var = str(u_name)
                    break

            for v_name in possible_v:
                if v_name in ds.data_vars:
                    v_var = str(v_name)
                    break

        if u_var is None or v_var is None:
            raise ValueError("Could not find velocity components in dataset")

        if plot_component == "u":
            return self.plot_boundary_data(
                file_path, variable=u_var, time_idx=time_idx,
                level_idx=level_idx, ax=ax, **kwargs
            )
        elif plot_component == "v":
            return self.plot_boundary_data(
                file_path, variable=v_var, time_idx=time_idx,
                level_idx=level_idx, ax=ax, **kwargs
            )
        elif plot_component == "magnitude":
            return self._plot_velocity_magnitude(
                ds, u_var, v_var, time_idx, level_idx, ax, **kwargs
            )
        elif plot_component == "vectors":
            return self._plot_velocity_vectors(
                ds, u_var, v_var, time_idx, level_idx, ax, **kwargs
            )
        else:
            raise ValueError(f"Unknown velocity component: {plot_component}")

    def plot_elevation_2d(
        self,
        time_idx: int = 0,
        ax: Optional[Axes] = None,
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot 2D elevation boundary data using file_map.

        Parameters
        ----------
        time_idx : int, optional
            Time index to plot. Default is 0.
        ax : Optional[Axes]
            Existing axes to plot on
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        file_path = self.file_map.get("elevation_2d")
        if not file_path:
            raise ValueError("elevation_2d file not found in file_map.")
        return self.plot_boundary_data(
            file_path, variable="elevation", time_idx=time_idx, ax=ax, **kwargs
        )

    def plot_atmospheric_spatial(
        self,
        variable: str = "air",
        parameter: Optional[str] = None,
        time_idx: int = 0,
        level_idx: int = 0,
        ax: Optional[Axes] = None,
        file_path: Optional[Union[str, Path]] = None,
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot spatial distribution of atmospheric forcing data.
        """
        fig, ax = self.create_figure(ax=ax, **kwargs)

        # Robust file discovery
        ds = None
        file_key = variable.lower()
        file_path_map = self.file_map.get(file_key)
        if file_path_map:
            ds = load_schism_data(file_path_map)
        elif file_path:
            ds = load_schism_data(file_path)
        else:
            try:
                ds = self._get_atmospheric_dataset(variable)
            except Exception as e:
                raise RuntimeError(f"Atmospheric data file for '{variable}' not found in file_map, kwargs, or config: {e}")
        if ds is None:
            raise RuntimeError(f"Atmospheric data for '{variable}' could not be loaded.")


        # Parameter mapping - include both standard names and ERA5 names
        parameter_map = {
            "air": ["prmsl", "msl", "uwind", "u10", "vwind", "v10", "stmp", "spfh"],
            "rad": ["dlwrf", "dswrf"],
            "prc": ["prate"],
        }

        # Find parameter if not specified
        if parameter is None:
            if variable in parameter_map:
                for param in parameter_map[variable]:
                    if param in ds.data_vars:
                        parameter = param
                        break

            if parameter is None and len(ds.data_vars) > 0:
                parameter = list(ds.data_vars)[0]

        # Check if we're plotting wind vectors
        if parameter == "wind_vectors" or (variable == "air" and parameter == "air"):
            return self._plot_atmospheric_wind_vectors(
                ds, time_idx, level_idx, ax, fig, **kwargs
            )

        if parameter not in ds.data_vars:
            raise ValueError(f"Parameter '{parameter}' not found in dataset")

        # Get coordinates
        lons = ds["lon"].values if "lon" in ds else ds["longitude"].values
        lats = ds["lat"].values if "lat" in ds else ds["latitude"].values

        # Get data for specified time and level
        data = ds[parameter][time_idx].values
        if len(data.shape) > 2:  # 3D data
            data = data[level_idx]

        # Create meshgrid if needed
        if len(lons.shape) == 1 and len(lats.shape) == 1:
            lons, lats = np.meshgrid(lons, lats)

        # Filter out figure-related kwargs that shouldn't go to pcolormesh
        # Only allow valid matplotlib Axes.pcolormesh arguments
        valid_pcolormesh_args = [
            'alpha', 'cmap', 'edgecolors', 'shading', 'snap', 'vmin', 'vmax', 'antialiased', 'rasterized', 'linewidths', 'norm', 'zorder'
        ]
        plot_kwargs = {k: v for k, v in kwargs.items() if k in valid_pcolormesh_args}
        # Warn about any unexpected kwargs
        unexpected = [k for k in kwargs if k not in valid_pcolormesh_args and k not in ['figsize', 'dpi', 'save_path', 'use_cartopy']]
        if unexpected:
            logger.warning(f"Ignoring unexpected plotting kwargs: {unexpected}")

        # Plot data
        im = ax.pcolormesh(lons, lats, data, cmap=self.plot_config.cmap, **plot_kwargs)

        # Add colorbar
        units = ds[parameter].attrs.get("units", "")
        label = f"{parameter} ({units})" if units else parameter
        cbar = self.add_colorbar(fig, ax, im, label=label)

        # Add grid boundaries if available
        if hasattr(self, 'grid') and self.grid is not None:
            try:
                add_boundary_overlay(ax, self.grid)
            except Exception as e:
                logger.warning(f"Could not add grid boundaries: {e}")

        # Set extent
        extent = get_geographic_extent(lons, lats)
        ax.set_xlim(extent[0], extent[1])
        ax.set_ylim(extent[2], extent[3])

        # Set title
        try:
            time_str = str(ds["time"].values[time_idx])
            title = f"{parameter} - {time_str}"
        except:
            title = parameter

        return self.finalize_plot(fig, ax, title=title)

    def plot_atmospheric_timeseries(
        self,
        variable: str = "air",
        parameter: Optional[str] = None,
        lat: Optional[float] = None,
        lon: Optional[float] = None,
        location_idx: Optional[int] = None,
        level_idx: int = 0,
        ax: Optional[Axes] = None,
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot time series of atmospheric data at a specific location.

        Parameters
        ----------
        variable : str, optional
            Type of atmospheric data ('air', 'rad', 'prc'). Default is 'air'.
        parameter : Optional[str]
            Specific parameter to plot. Use 'wind_speed' for wind speed calculation.
        lat : Optional[float]
            Latitude of point to extract.
        lon : Optional[float]
            Longitude of point to extract.
        location_idx : Optional[int]
            Index of location to plot. If None, nearest to (lat, lon) is used.
        level_idx : int, optional
            Vertical level index for 3D variables. Default is 0.
        ax : Optional[Axes]
            Existing axes to plot on
        **kwargs : dict
            Additional plotting parameters. For wind speed:
            - uwind_name: name of u-wind variable (default: 'uwind')
            - vwind_name: name of v-wind variable (default: 'vwind')

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        fig, ax = self.create_figure(ax=ax, use_cartopy=False, **kwargs)

        # Get dataset
        file_path = kwargs.get('file_path')
        if file_path:
            ds = load_schism_data(file_path)
        else:
            raise RuntimeError("Atmospheric data file_path must be provided for plotting")

        # Find parameter
        if parameter is None:
            parameter = list(ds.data_vars)[0]

        # Check if we're plotting wind speed
        if parameter == "wind_speed" or (variable == "air" and parameter == "air"):
            return self._plot_atmospheric_wind_speed_timeseries(
                ds, lat, lon, location_idx, level_idx, ax, fig, **kwargs
            )

        # Get coordinates
        lons = ds["lon"].values if "lon" in ds else ds["longitude"].values
        lats = ds["lat"].values if "lat" in ds else ds["latitude"].values

        # Find location index
        if location_idx is None:
            if lat is None or lon is None:
                raise ValueError("Either location_idx or both lat and lon must be provided")

            if len(lons.shape) == 1 and len(lats.shape) == 1:
                lon_idx = np.abs(lons - lon).argmin()
                lat_idx = np.abs(lats - lat).argmin()
                location_idx = (lat_idx, lon_idx)
            else:
                points = np.vstack((lons.flatten(), lats.flatten())).T
                tree = cKDTree(points)
                _, location_idx = tree.query([lon, lat])

        # Extract time series
        times = ds["time"].values

        if isinstance(location_idx, tuple):
            values = ds[parameter].isel(
                {ds[parameter].dims[1]: location_idx[0],
                 ds[parameter].dims[2]: location_idx[1]}
            ).values
        else:
            values = ds[parameter].flatten()[location_idx::len(lons.flatten())]

        # Handle 3D data
        if len(values.shape) > 1:
            values = values[:, level_idx]

        # Plot time series
        ax.plot(times, values, **kwargs)

        # Set labels
        units = ds[parameter].attrs.get("units", "")
        ylabel = f"{parameter} ({units})" if units else parameter
        ax.set_ylabel(ylabel)
        ax.set_xlabel("Time")

        # Format dates
        fig.autofmt_xdate()

        # Set title
        if isinstance(location_idx, tuple):
            loc_lat = lats[location_idx[0]]
            loc_lon = lons[location_idx[1]]
        else:
            loc_lat = lats.flatten()[location_idx]
            loc_lon = lons.flatten()[location_idx]

        title = f"{parameter} at ({loc_lat:.2f}°, {loc_lon:.2f}°)"

        return self.finalize_plot(fig, ax, title=title)

    def plot_tidal_boundaries(
        self,
        ax: Optional[Axes] = None,
        colors: Dict[str, str] = None,
        linewidth: float = 2.0,
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot tidal boundaries.

        Parameters
        ----------
        ax : Optional[Axes]
            Existing axes to plot on
        colors : Dict[str, str], optional
            Colors for different boundary types
        linewidth : float, optional
            Line width for boundaries. Default is 2.0.
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        fig, ax = self.create_figure(ax=ax, **kwargs)

        if colors is None:
            colors = {"tidal": "blue", "ocean": "red", "land": "green"}

        try:
            grid = self.grid

            # Plot regular boundaries first
            add_boundary_overlay(ax, grid, boundary_colors=colors, linewidth=linewidth)

            # Add tidal-specific boundaries if available in config
            if (self.config and hasattr(self.config, 'data') and
                hasattr(self.config.data, 'boundary_conditions') and
                self.config.data.boundary_conditions is not None):
                bc = self.config.data.boundary_conditions
                if (hasattr(bc, 'setup_type') and bc.setup_type in ['tidal', 'hybrid'] and
                    hasattr(bc, 'tidal_data') and getattr(bc, 'tidal_data', None) and getattr(bc.tidal_data, 'constituents', None)):
                    tidal_data = getattr(bc, 'tidal_data', None)
                    constituents = getattr(tidal_data, 'constituents', None)
                    if not constituents:
                        constituents = ['M2', 'S2', 'N2']
                    logger.info(f"Plotting tidal boundaries with constituents: {', '.join(constituents)}")
                    # Additional tidal boundary plotting could be implemented here
                else:
                    logger.info("Boundary conditions exist but no tidal setup found")
            else:
                logger.info("No boundary conditions found in config")

        except Exception as e:
            logger.error(f"Error plotting tidal boundaries: {e}")
            raise

        return self.finalize_plot(fig, ax, title="Tidal Boundaries")

    def plot_tidal_inputs_at_points(
        self,
        sample_points: Optional[List[Tuple[float, float]]] = None,
        n_points: int = 4,
        time_hours: float = 24.0,
        ax: Optional[Axes] = None,
        plot_type: str = "elevation",
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot tidal inputs (elevation or velocity) time series at sample grid points.

        Parameters
        ----------
        sample_points : Optional[List[Tuple[float, float]]]
            List of (lon, lat) coordinates for sample points. If None, representative
            points are automatically selected from boundary nodes.
        n_points : int, optional
            Number of sample points to use if sample_points is None. Default is 4.
        time_hours : float, optional
            Duration in hours for the time series. Default is 24.0 hours.
        ax : Optional[Axes]
            Existing axes to plot on
        plot_type : str, optional
            Type of plot: 'elevation', 'velocity_u', 'velocity_v', 'velocity_magnitude'.
            Default is 'elevation'.
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        fig, ax = self.create_figure(ax=ax, use_cartopy=False, **kwargs)

        try:
            # Check if we have tidal boundary conditions in config
            if not (self.config and hasattr(self.config, 'data') and
                    hasattr(self.config.data, 'boundary_conditions') and
                    self.config.data.boundary_conditions is not None):
                raise RuntimeError("No tidal boundary conditions found in configuration")

            bc = self.config.data.boundary_conditions
            if not (hasattr(bc, 'setup_type') and bc.setup_type in ['tidal', 'hybrid'] and
                    hasattr(bc, 'tidal_data') and getattr(bc, 'tidal_data', None) and getattr(bc.tidal_data, 'constituents', None)):
                raise RuntimeError("No tidal constituents found in boundary conditions")

            # Get tidal data files
            if not (hasattr(bc, 'tidal_data') and bc.tidal_data):
                raise RuntimeError("No tidal data files specified")

            # Import required modules
            import xarray as xr
            import numpy as np
            from datetime import datetime, timedelta
            from .utils import add_grid_overlay, add_boundary_overlay

            # Get sample points
            if sample_points is None:
                sample_points = self._get_representative_boundary_points(n_points)

            if sample_points is None or len(sample_points) == 0:
                raise RuntimeError("No boundary points available for sampling")

            # Add grid and boundary overlays for spatial context if grid is available
            if hasattr(self, 'grid') and self.grid is not None:
                try:
                    add_grid_overlay(ax, self.grid, alpha=0.2, color='lightgray', linewidth=0.3)
                    add_boundary_overlay(ax, self.grid, boundary_colors={"ocean": "red", "land": "darkgreen", "tidal": "blue"}, linewidth=2.5)
                except Exception as e:
                    logger.warning(f"Could not add grid/boundary overlays to time series panel: {e}")

            # Create standardized time array
            dt = 0.5  # 30-minute intervals
            times = self._compute_standardized_time_axis(time_hours, dt)
            n_times = len(times)

            # Get constituents
            tidal_data = getattr(bc, "tidal_data", None)
            constituents = getattr(tidal_data, "constituents", None)
            if not constituents:
                constituents = ['M2', 'S2', 'N2']
            logger.info(f"Plotting tidal inputs for constituents: {', '.join(constituents)}")

            # Load tidal data and compute time series
            if plot_type == "elevation":
                data_file = bc.tidal_data.elevations
                time_series_data = self._compute_tidal_elevation_timeseries(
                    data_file, sample_points, constituents, times
                )
                ylabel = "Elevation (m)"
                title_suffix = "Elevation"
            elif plot_type in ["velocity_u", "velocity_v", "velocity_magnitude"]:
                data_file = bc.tidal_data.velocities
                time_series_data = self._compute_tidal_velocity_timeseries(
                    data_file, sample_points, constituents, times, plot_type
                )
                if plot_type == "velocity_u":
                    ylabel = "U Velocity (m/s)"
                    title_suffix = "U Velocity"
                elif plot_type == "velocity_v":
                    ylabel = "V Velocity (m/s)"
                    title_suffix = "V Velocity"
                else:
                    ylabel = "Velocity Magnitude (m/s)"
                    title_suffix = "Velocity Magnitude"
            else:
                raise ValueError(f"Unsupported plot_type: {plot_type}")

            # Plot time series for each point
            colors = plt.get_cmap('tab10')(np.linspace(0, 1, len(sample_points)))

            for i, ((lon, lat), color) in enumerate(zip(sample_points, colors)):
                if i < len(time_series_data):
                    ax.plot(times, time_series_data[i], color=color, linewidth=2,
                           label=f"Point {i+1} ({lon:.2f}0, {lat:.2f}0)")

            # Format plot
            ax.set_xlabel("Time (hours)")
            ax.set_ylabel(ylabel)
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            ax.grid(True, alpha=0.3)

            # Add constituent information
            const_text = f"Constituents: {', '.join(constituents)}"
            ax.text(0.02, 0.98, const_text, transform=ax.transAxes,
                   verticalalignment='top', fontsize=10,
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7))

        except Exception as e:
            logger.error(f"Error plotting tidal inputs: {e}")
            raise RuntimeError(f"Error plotting tidal inputs: {str(e)}")
        # No plot is returned if error is raised above.



    def _get_representative_boundary_points(self, n_points: int) -> List[Tuple[float, float]]:
        """Get representative boundary points for tidal input sampling."""
        if not self.grid:
            raise RuntimeError("Grid object required for representative boundary points")

        hgrid = self.grid.pylibs_hgrid if hasattr(self.grid, 'pylibs_hgrid') else self.grid

        # Ensure boundaries are computed
        if not hasattr(hgrid, 'nob'):
            if getattr(hgrid, 'compute_bnd', None):
                hgrid.compute_bnd()
            elif getattr(hgrid, 'compute_all', None):
                hgrid.compute_all()

        # Get open boundary nodes
        boundary_nodes = getattr(hgrid, 'iobn', None)
        if boundary_nodes is not None and len(boundary_nodes) > 0:
            boundary_nodes = boundary_nodes[0]
            n_boundary = len(boundary_nodes)
            if n_boundary == 0:
                raise RuntimeError("No boundary nodes found in grid")
            indices = np.linspace(0, n_boundary - 1, min(n_points, n_boundary), dtype=int)
            sample_points = []
            hgrid_x = getattr(hgrid, 'x', None)
            hgrid_y = getattr(hgrid, 'y', None)
            if hgrid_x is None or hgrid_y is None:
                raise RuntimeError("Grid missing x or y coordinates")
            for idx in indices:
                node_idx = int(boundary_nodes[idx])
                if 0 <= node_idx < len(hgrid_x):
                    lon = float(hgrid_x[node_idx])
                    lat = float(hgrid_y[node_idx])
                    if not (np.isnan(lon) or np.isnan(lat) or np.isinf(lon) or np.isinf(lat)):
                        sample_points.append((lon, lat))
            if sample_points:
                return sample_points

        # If no boundary nodes found, fail immediately
        raise RuntimeError("No boundary nodes found in grid; cannot extract representative boundary points.")

    def _compute_tidal_elevation_timeseries(
        self,
        tidal_file: str,
        sample_points: List[Tuple[float, float]],
        constituents: List[str],
        times: np.ndarray
    ) -> List[np.ndarray]:
        """Compute tidal elevation time series at sample points."""
        import xarray as xr
        import numpy as np

        logger.info(f"Loading tidal elevation data from: {tidal_file}")

        try:
            # Load TPXO elevation data
            ds = xr.open_dataset(tidal_file)
            logger.info(f"Dataset variables: {list(ds.variables.keys())}")
            logger.info(f"Dataset dimensions: {dict(ds.dims)}")

            # Get constituent names from file
            file_constituents = []
            if 'con' in ds.variables:
                cons = ds.variables["con"][:]
                logger.info(f"Found {len(cons)} constituents in file")
                for i in range(len(cons)):
                    const_name = self._decode_constituent_name(cons[i])
                    file_constituents.append(const_name)
                    logger.info(f"Constituent {i}: {const_name}")
            else:
                logger.warning("No 'con' variable found in dataset")

            # Get coordinates
            if "lon_z" in ds.variables and "lat_z" in ds.variables:
                lon_grid = ds["lon_z"].values
                lat_grid = ds["lat_z"].values
                logger.info(f"Grid coordinates: lon_z shape={lon_grid.shape}, lat_z shape={lat_grid.shape}")
                logger.info(f"Longitude range: [{lon_grid.min():.3f}, {lon_grid.max():.3f}]")
                logger.info(f"Latitude range: [{lat_grid.min():.3f}, {lat_grid.max():.3f}]")
            else:
                logger.error("Required coordinates 'lon_z' and 'lat_z' not found in dataset")
                ds.close()
                raise RuntimeError("Required coordinates 'lon_z' and 'lat_z' not found in dataset")

            # Check for required data variables
            if "ha" not in ds.variables or "hp" not in ds.variables:
                logger.error("Required variables 'ha' (amplitude) or 'hp' (phase) not found in dataset")
                ds.close()
                raise RuntimeError("Required variables 'ha' (amplitude) or 'hp' (phase) not found in dataset")

            # Initialize time series for each point
            time_series_list = []

            for point_idx, (point_lon, point_lat) in enumerate(sample_points):
                logger.info(f"Processing point {point_idx+1}: ({point_lon:.3f}, {point_lat:.3f})")
                elevation_ts = np.zeros(len(times))
                point_has_data = False

                # Process each constituent
                for const in constituents:
                    const_lower = const.lower()
                    if const_lower in [c.lower() for c in file_constituents]:
                        # Find matching constituent (case insensitive)
                        const_idx = None
                        for i, fc in enumerate(file_constituents):
                            if fc.lower() == const_lower:
                                const_idx = i
                                break

                        if const_idx is not None:
                            # Get amplitude and phase
                            amp = ds["ha"][const_idx].values
                            phase = ds["hp"][const_idx].values

                            logger.info(f"  Processing constituent {const}: amp shape={amp.shape}, phase shape={phase.shape}")

                            # Interpolate to point location
                            amp_interp = self._interpolate_to_point(lon_grid, lat_grid, amp, point_lon, point_lat)
                            phase_interp = self._interpolate_to_point(lon_grid, lat_grid, phase, point_lon, point_lat)

                            logger.info(f"  Interpolated values: amp={amp_interp:.4f}, phase={phase_interp:.4f}")

                            if not np.isnan(amp_interp) and not np.isnan(phase_interp) and amp_interp > 0:
                                # Get tidal frequency (cycles per hour)
                                freq = self._get_tidal_frequency(const)

                                # Compute time series: A * cos(ωt - φ)
                                phase_rad = np.deg2rad(phase_interp)
                                omega = 2 * np.pi * freq  # rad/hour
                                constituent_ts = amp_interp * np.cos(omega * times - phase_rad)

                                elevation_ts += constituent_ts
                                point_has_data = True

                                logger.info(f"  Added constituent {const}: max={constituent_ts.max():.4f}, min={constituent_ts.min():.4f}")
                            else:
                                logger.warning(f"  Invalid interpolated values for constituent {const}")
                    else:
                        logger.warning(f"  Constituent {const} not found in file constituents")

                if point_has_data:
                    logger.info(f"Point {point_idx+1} final time series: max={elevation_ts.max():.4f}, min={elevation_ts.min():.4f}")
                else:
                    logger.warning(f"Point {point_idx+1} has no valid data - using zero values")
                    # Use zero values instead of synthetic data
                    elevation_ts = np.zeros(len(times))

                time_series_list.append(elevation_ts)

            ds.close()
            logger.info(f"Successfully computed elevation time series for {len(time_series_list)} points")
            return time_series_list

        except Exception as e:
            logger.error(f"Error computing tidal elevation time series: {e}")
            import traceback
            logger.error(traceback.format_exc())

            # Raise error instead of returning synthetic fallback
            logger.error("Failed to compute tidal elevation time series - no valid data")
            raise RuntimeError("Failed to compute tidal elevation time series - no valid data")

    def _compute_tidal_velocity_timeseries(
        self,
        tidal_file: str,
        sample_points: List[Tuple[float, float]],
        constituents: List[str],
        times: np.ndarray,
        velocity_component: str
    ) -> List[np.ndarray]:
        """Compute tidal velocity time series at sample points."""
        import xarray as xr
        import numpy as np

        # Load TPXO velocity data
        ds = xr.open_dataset(tidal_file)

        # Get constituent names from file
        file_constituents = []
        if 'con' in ds.variables:
            cons = ds.variables["con"][:]
            for i in range(len(cons)):
                const_name = self._decode_constituent_name(cons[i])
                file_constituents.append(const_name)

        # Get coordinates (u and v may have different grids)
        if velocity_component in ["velocity_u", "velocity_magnitude"]:
            lon_grid = ds["lon_u"].values
            lat_grid = ds["lat_u"].values
        else:
            lon_grid = ds["lon_v"].values
            lat_grid = ds["lat_v"].values

        # Initialize time series for each point
        time_series_list = []

        for point_lon, point_lat in sample_points:
            velocity_ts = np.zeros(len(times))
            amp = None
            phase = None
            u_ts = None
            v_ts = None

            if velocity_component == "velocity_magnitude":
                u_ts = np.zeros(len(times))
                v_ts = np.zeros(len(times))

            # Process each constituent
            for const in constituents:
                const_lower = const.lower()
                if const_lower in file_constituents:
                    const_idx = file_constituents.index(const_lower)

                    if velocity_component == "velocity_u":
                        amp = ds["ua"][const_idx].values
                        phase = ds["up"][const_idx].values
                        lon_grid = ds["lon_u"].values
                        lat_grid = ds["lat_u"].values

                    elif velocity_component == "velocity_v":
                        amp = ds["va"][const_idx].values
                        phase = ds["vp"][const_idx].values
                        lon_grid = ds["lon_v"].values
                        lat_grid = ds["lat_v"].values

                    elif velocity_component == "velocity_magnitude":
                        u_amp = ds["ua"][const_idx].values
                        u_phase = ds["up"][const_idx].values
                        v_amp = ds["va"][const_idx].values
                        v_phase = ds["vp"][const_idx].values
                        lon_u = ds["lon_u"].values
                        lat_u = ds["lat_u"].values
                        u_amp_interp = self._interpolate_to_point(lon_u, lat_u, u_amp, point_lon, point_lat)
                        u_phase_interp = self._interpolate_to_point(lon_u, lat_u, u_phase, point_lon, point_lat)
                        lon_v = ds["lon_v"].values
                        lat_v = ds["lat_v"].values
                        v_amp_interp = self._interpolate_to_point(lon_v, lat_v, v_amp, point_lon, point_lat)
                        v_phase_interp = self._interpolate_to_point(lon_v, lat_v, v_phase, point_lon, point_lat)
                        if (not np.isnan(u_amp_interp) and not np.isnan(u_phase_interp) and
                            not np.isnan(v_amp_interp) and not np.isnan(v_phase_interp)):
                            freq = self._get_tidal_frequency(const)
                            omega = 2 * np.pi * freq  # rad/hour
                            u_phase_rad = np.deg2rad(u_phase_interp)
                            v_phase_rad = np.deg2rad(v_phase_interp)
                            u_constituent = u_amp_interp * np.cos(omega * times - u_phase_rad)
                            v_constituent = v_amp_interp * np.cos(omega * times - v_phase_rad)
                            u_ts += u_constituent
                            v_ts += v_constituent
                        continue  # Skip the general interpolation below

                    # General interpolation for U or V component
                    if amp is not None and phase is not None:
                        amp_interp = self._interpolate_to_point(lon_grid, lat_grid, amp, point_lon, point_lat)
                        phase_interp = self._interpolate_to_point(lon_grid, lat_grid, phase, point_lon, point_lat)
                        if not np.isnan(amp_interp) and not np.isnan(phase_interp):
                            freq = self._get_tidal_frequency(const)
                            omega = 2 * np.pi * freq  # rad/hour
                            phase_rad = np.deg2rad(phase_interp)
                            constituent_ts = amp_interp * np.cos(omega * times - phase_rad)
                            velocity_ts += constituent_ts

            if velocity_component == "velocity_magnitude" and u_ts is not None and v_ts is not None:
                velocity_ts = np.sqrt(u_ts**2 + v_ts**2)

            if not np.any(velocity_ts):
                raise RuntimeError(f"No valid tidal velocity data found for point ({point_lon}, {point_lat})")
            time_series_list.append(velocity_ts)

        ds.close()
        return time_series_list

    def _interpolate_to_point(self, lon_grid, lat_grid, data, target_lon, target_lat):
        """Interpolate gridded data to a single point using nearest neighbor."""
        import numpy as np

        # Validate inputs
        if np.isnan(target_lon) or np.isnan(target_lat):
            logger.warning(f"Invalid target coordinates: ({target_lon}, {target_lat})")
            return np.nan

        # Handle longitude wrapping (convert to 0-360 if grid uses that convention)
        if lon_grid.max() > 180 and target_lon < 0:
            target_lon += 360
        elif lon_grid.max() <= 180 and target_lon > 180:
            target_lon -= 360

        # Check if point is within reasonable distance of grid (use 5 degrees as threshold)
        lon_range = [lon_grid.min(), lon_grid.max()]
        lat_range = [lat_grid.min(), lat_grid.max()]

        if (target_lon < lon_range[0] - 5 or target_lon > lon_range[1] + 5 or
            target_lat < lat_range[0] - 5 or target_lat > lat_range[1] + 5):
            logger.warning(f"Target point ({target_lon:.3f}, {target_lat:.3f}) is far from grid bounds: "
                          f"lon=[{lon_range[0]:.3f}, {lon_range[1]:.3f}], lat=[{lat_range[0]:.3f}, {lat_range[1]:.3f}]")
            # Return NaN for points too far from grid
            return np.nan

        logger.debug(f"Interpolating to point: ({target_lon:.3f}, {target_lat:.3f})")
        logger.debug(f"Data grid shape: {data.shape}")
        logger.debug(f"Lon grid shape: {lon_grid.shape}, range: [{lon_grid.min():.3f}, {lon_grid.max():.3f}]")
        logger.debug(f"Lat grid shape: {lat_grid.shape}, range: [{lat_grid.min():.3f}, {lat_grid.max():.3f}]")

        # Handle NaN values
        valid_mask = ~np.isnan(data)
        valid_count = np.sum(valid_mask)
        logger.debug(f"Valid data points: {valid_count}/{data.size}")

        if not np.any(valid_mask):
            logger.warning("No valid data points found")
            return np.nan

        # Find nearest grid point
        if len(lon_grid.shape) == 1 and len(lat_grid.shape) == 1:
            # Regular grid (1D coordinate arrays)
            try:
                # Check if target point is within reasonable distance of grid bounds
                lon_buffer = (lon_grid.max() - lon_grid.min()) * 0.1  # 10% buffer
                lat_buffer = (lat_grid.max() - lat_grid.min()) * 0.1  # 10% buffer

                if (target_lon < lon_grid.min() - lon_buffer or target_lon > lon_grid.max() + lon_buffer or
                    target_lat < lat_grid.min() - lat_buffer or target_lat > lat_grid.max() + lat_buffer):
                    logger.warning(f"Target point ({target_lon:.3f}, {target_lat:.3f}) is outside grid bounds with buffer")
                    # Find closest boundary point
                    target_lon = np.clip(target_lon, lon_grid.min(), lon_grid.max())
                    target_lat = np.clip(target_lat, lat_grid.min(), lat_grid.max())

                lon_idx = np.abs(lon_grid - target_lon).argmin()
                lat_idx = np.abs(lat_grid - target_lat).argmin()

                logger.debug(f"Grid indices: lon_idx={lon_idx}, lat_idx={lat_idx}")

                # Validate indices and data dimensions
                if (0 <= lon_idx < len(lon_grid) and 0 <= lat_idx < len(lat_grid)):
                    if len(data.shape) == 2:
                        if lat_idx < data.shape[0] and lon_idx < data.shape[1]:
                            value = data[lat_idx, lon_idx] if valid_mask[lat_idx, lon_idx] else np.nan
                            logger.debug(f"Interpolated value: {value}")
                            return value
                    elif len(data.shape) == 1:
                        # Flattened data
                        flat_idx = lat_idx * len(lon_grid) + lon_idx
                        if flat_idx < len(data):
                            value = data[flat_idx] if valid_mask[flat_idx] else np.nan
                            logger.debug(f"Interpolated value (flat): {value}")
                            return value

                logger.warning("Invalid array indexing")
                return np.nan
            except (IndexError, ValueError) as e:
                logger.warning(f"Error in regular grid interpolation: {e}")
                return np.nan
        else:
            # Irregular grid (2D coordinate arrays) - find closest point
            try:
                # Check if coordinate arrays match data shape
                if lon_grid.shape != data.shape or lat_grid.shape != data.shape:
                    logger.warning(f"Coordinate shape mismatch: lon={lon_grid.shape}, lat={lat_grid.shape}, data={data.shape}")
                    return np.nan

                dist_sq = (lon_grid - target_lon)**2 + (lat_grid - target_lat)**2
                # Only consider valid data points
                dist_sq[~valid_mask] = np.inf

                if np.all(np.isinf(dist_sq)):
                    logger.warning("No valid nearby points found")
                    return np.nan

                min_idx = np.unravel_index(np.argmin(dist_sq), dist_sq.shape)
                min_dist = np.sqrt(dist_sq[min_idx])
                value = data[min_idx]

                logger.debug(f"Nearest point at distance {min_dist:.3f}, value: {value}")
                return value
            except (IndexError, ValueError) as e:
                logger.warning(f"Error in irregular grid interpolation: {e}")
                return np.nan

    def _decode_constituent_name(self, const_data) -> str:
        """
        Robustly decode constituent name from various data types.

        Parameters
        ----------
        const_data : various
            Constituent data from netCDF file (bytes, string, array, etc.)

        Returns
        -------
        str
            Decoded constituent name in lowercase
        """
        import numpy as np

        # Handle xarray Variables by extracting the values
        if hasattr(const_data, 'values'):
            const_data = const_data.values

        # Handle numpy scalars and arrays
        if hasattr(const_data, 'item'):
            try:
                const_data = const_data.item()
            except ValueError:
                # Multi-element array, keep as is
                pass

        # Handle different data types
        if isinstance(const_data, bytes):
            # Direct bytes object
            return const_data.decode("utf-8").strip().lower()
        elif isinstance(const_data, str):
            # Direct string
            return const_data.strip().lower()
        elif isinstance(const_data, np.bytes_):
            # Numpy bytes object
            return const_data.decode("utf-8").strip().lower()
        elif hasattr(const_data, '__iter__') and not isinstance(const_data, str):
            # Array of characters/bytes
            try:
                if hasattr(const_data, 'shape') and len(const_data.shape) == 0:
                    # 0-d array - extract the scalar value
                    item = const_data.item()
                    if isinstance(item, bytes):
                        return item.decode("utf-8").strip().lower()
                    else:
                        return str(item).strip().lower()
                else:
                    # Multi-dimensional array of characters
                    const_chars = []
                    for c in const_data.flat:
                        if isinstance(c, (bytes, np.bytes_)):
                            const_chars.append(c.decode("utf-8"))
                        elif hasattr(c, 'item'):
                            char_val = c.item()
                            if isinstance(char_val, (bytes, np.bytes_)):
                                const_chars.append(char_val.decode("utf-8"))
                            else:
                                const_chars.append(str(char_val))
                        else:
                            const_chars.append(str(c))
                    return "".join(const_chars).strip().lower()
            except Exception as e:
                logger.warning(f"Error decoding array-like constituent: {e}")
                # Fallback: convert to string
                return str(const_data).strip().lower()
        else:
            # Fallback for other types
            return str(const_data).strip().lower()

    def _get_tidal_frequency(self, constituent):
        """Get tidal frequency in cycles per hour for common constituents."""
        # Tidal frequencies in cycles per hour based on standard periods
        frequencies = {
            'M2': 1.0 / 12.421,  # Principal lunar semi-diurnal: 12.421 hours
            'S2': 1.0 / 12.000,  # Principal solar semi-diurnal: 12.000 hours
            'N2': 1.0 / 12.658,  # Lunar elliptic semi-diurnal: 12.658 hours
            'K2': 1.0 / 11.967,  # Lunisolar semi-diurnal: 11.967 hours
            'K1': 1.0 / 23.934,  # Lunar diurnal: 23.934 hours
            'O1': 1.0 / 25.819,  # Principal lunar diurnal: 25.819 hours
            'P1': 1.0 / 24.066,  # Principal solar diurnal: 24.066 hours
            'Q1': 1.0 / 26.868,  # Lunar elliptic diurnal: 26.868 hours
        }

        # Check if constituent is a string name
        if isinstance(constituent, str) and not constituent.replace('.', '').replace('e', '').replace('-', '').replace('+', '').isdigit():
            const_upper = constituent.upper().strip()
            if const_upper in frequencies:
                logger.debug(f"Found frequency for constituent {const_upper}: {frequencies[const_upper]:.6e}")
                return frequencies[const_upper]
        else:
            # Try to parse as numerical frequency and map to constituent
            try:
                freq_value = float(constituent)
                logger.debug(f"Parsing numerical frequency: {freq_value}")

                # Convert to cycles per hour if it's in cycles per second
                if freq_value < 1e-3:  # Likely in cycles/second
                    freq_value *= 3600
                    logger.debug(f"Converted to cycles/hour: {freq_value}")

                # Find closest matching constituent frequency
                min_diff = float('inf')
                best_match = 'M2'
                for const_name, const_freq in frequencies.items():
                    diff = abs(const_freq - freq_value)
                    if diff < min_diff:
                        min_diff = diff
                        best_match = const_name

                # Only warn if the difference is significant (more than 1% of M2 frequency)
                if min_diff > frequencies['M2'] * 0.01:
                    logger.warning(f"Unknown constituent {constituent}, using {best_match} frequency (diff={min_diff:.2e})")
                else:
                    logger.info(f"Mapped frequency {constituent} to constituent {best_match}")

                return frequencies[best_match]
            except (ValueError, TypeError) as e:
                logger.warning(f"Could not parse constituent frequency {constituent}: {e}")

        # Default to M2 frequency if constituent not found
        logger.warning(f"Unknown constituent {constituent}, using M2 frequency")
        return frequencies['M2']

    def _frequency_to_constituent_name(self, frequency):
        """Map frequency value to constituent name."""
        frequencies = {
            'M2': 1.40519e-4 * 3600,
            'S2': 1.45444e-4 * 3600,
            'N2': 1.37880e-4 * 3600,
            'K2': 1.45842e-4 * 3600,
            'K1': 0.72921e-4 * 3600,
            'O1': 0.67598e-4 * 3600,
            'P1': 0.72523e-4 * 3600,
            'Q1': 0.64959e-4 * 3600,
        }

        try:
            freq_value = float(frequency)
            # Convert to cycles per hour if it's in cycles per second
            if freq_value < 1e-3:  # Likely in cycles/second
                freq_value *= 3600

            # Find closest matching constituent frequency
            min_diff = float('inf')
            best_match = 'M2'
            for const_name, const_freq in frequencies.items():
                diff = abs(const_freq - freq_value)
                if diff < min_diff:
                    min_diff = diff
                    best_match = const_name

            return best_match
        except (ValueError, TypeError):
            return str(frequency)

    def plot_schism_boundary_data(
        self,
        bctides_file: Union[str, Path],
        plot_type: str = "elevation",
        time_hours: float = 24.0,
        ax: Optional[Axes] = None,
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot actual SCHISM boundary data from bctides.in file.

        This plots the processed boundary data that SCHISM will actually use,
        rather than the input TPXO data.

        Parameters
        ----------
        bctides_file : Union[str, Path]
            Path to bctides.in file
        plot_type : str, optional
            Type of plot: 'elevation', 'velocity', 'summary'. Default is 'elevation'.
        time_hours : float, optional
            Duration in hours for time series. Default is 24.0 hours.
        ax : Optional[Axes]
            Existing axes to plot on
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        fig, ax = self.create_figure(ax=ax, use_cartopy=False, **kwargs)

        try:
            import numpy as np
            from pathlib import Path

            bctides_file = Path(bctides_file)
            if not bctides_file.exists():
                raise RuntimeError(f"Bctides file not found: {bctides_file}")
                # No plot is returned if error is raised above.

            # Parse bctides.in file
            boundary_data = self._parse_bctides_file(bctides_file)

            if not boundary_data:
                raise RuntimeError("No boundary data found in bctides.in file")
                # No plot is returned if error is raised above.

            # Create time series from harmonic constituents
            dt = 0.5  # 30-minute intervals
            n_times = int(time_hours / dt)
            times = np.arange(0, time_hours, dt)

            if plot_type == "elevation":
                self._plot_boundary_elevation_timeseries(ax, boundary_data, times)
                ylabel = "Elevation (m)"
                title = "SCHISM Boundary Elevation Time Series"
            elif plot_type == "velocity":
                self._plot_boundary_velocity_timeseries(ax, boundary_data, times)
                ylabel = "Velocity (m/s)"
                title = "SCHISM Boundary Velocity Time Series"
            elif plot_type == "summary":
                self._plot_boundary_data_summary(ax, boundary_data)
                ylabel = ""
                title = "SCHISM Boundary Data Summary"
            else:
                raise ValueError(f"Unsupported plot_type: {plot_type}")

            if plot_type in ["elevation", "velocity"]:
                ax.set_xlabel("Time (hours)")
                ax.set_ylabel(ylabel)
                ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                ax.grid(True, alpha=0.3)

        except Exception as e:
            logger.error(f"Error plotting SCHISM boundary data: {e}")
            raise RuntimeError(f"Error plotting boundary data: {str(e)}")

        return self.finalize_plot(fig, ax, title=title)

    def plot_tidal_amplitude_phase_maps(
        self,
        constituent: str = "M2",
        variable: str = "elevation",
        ax: Optional[Axes] = None,
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot spatial distribution of tidal amplitude and phase for a constituent.

        Parameters
        ----------
        constituent : str, optional
            Tidal constituent to plot. Default is "M2".
        variable : str, optional
            Variable to plot: 'elevation', 'velocity_u', 'velocity_v'. Default is 'elevation'.
        ax : Optional[Axes]
            Existing axes to plot on
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        try:
            # Check if we have tidal boundary conditions in config
            if not (self.config and hasattr(self.config, 'data') and
                    hasattr(self.config.data, 'boundary_conditions') and
                    self.config.data.boundary_conditions is not None):
                raise RuntimeError("No tidal boundary conditions found in configuration")

            bc = self.config.data.boundary_conditions
            if not (hasattr(bc, 'setup_type') and bc.setup_type in ['tidal', 'hybrid'] and
                    hasattr(bc, 'tidal_data') and getattr(bc, 'tidal_data', None) and getattr(bc.tidal_data, 'constituents', None)):
                raise RuntimeError("No tidal constituents found in boundary conditions")

            # Get tidal data files
            if not (hasattr(bc, 'tidal_data') and bc.tidal_data):
                raise RuntimeError("No tidal data files specified")

            import xarray as xr
            import numpy as np

            # Determine which file to use
            if variable == "elevation":
                data_file = bc.tidal_data.elevations
                amp_var = "ha"
                phase_var = "hp"
                lon_var = "lon_z"
                lat_var = "lat_z"
                units = "m"
            elif variable == "velocity_u":
                data_file = bc.tidal_data.velocities
                amp_var = "ua"
                phase_var = "up"
                lon_var = "lon_u"
                lat_var = "lat_u"
                units = "m/s"
            elif variable == "velocity_v":
                data_file = bc.tidal_data.velocities
                amp_var = "va"
                phase_var = "vp"
                lon_var = "lon_v"
                lat_var = "lat_v"
                units = "m/s"
            else:
                raise ValueError(f"Unsupported variable: {variable}")

            # Load TPXO data
            ds = xr.open_dataset(data_file)

            # Find constituent index
            file_constituents = []
            if 'con' in ds.variables:
                cons = ds.variables["con"][:]
                logger.info(f"Found {len(cons)} constituents in {variable} data file")
                for i in range(len(cons)):
                    const_name = self._decode_constituent_name(cons[i])
                    file_constituents.append(const_name)
                    logger.info(f"File constituent {i}: '{const_name}'")
            else:
                logger.warning("No 'con' variable found in dataset")

            const_lower = constituent.lower()
            logger.info(f"Looking for constituent '{const_lower}' in file constituents: {file_constituents}")

            # Find matching constituent (case insensitive)
            const_idx = None
            for i, fc in enumerate(file_constituents):
                if fc.lower() == const_lower:
                    const_idx = i
                    logger.info(f"Found matching constituent at index {i}: '{fc}'")
                    break

            if const_idx is None:
                raise RuntimeError(f"Constituent {constituent} not found in tidal data. Available: {', '.join(file_constituents)}")

            # Get data
            if lon_var not in ds.variables or lat_var not in ds.variables:
                raise RuntimeError(f"Required coordinates '{lon_var}' or '{lat_var}' not found in dataset")

            if amp_var not in ds.variables or phase_var not in ds.variables:
                raise RuntimeError(f"Required variables '{amp_var}' or '{phase_var}' not found in dataset")

            lon_grid = ds[lon_var].values
            lat_grid = ds[lat_var].values
            amplitude = ds[amp_var][const_idx].values
            phase = ds[phase_var][const_idx].values

            logger.info(f"Data shapes: lon={lon_grid.shape}, lat={lat_grid.shape}, amp={amplitude.shape}, phase={phase.shape}")
            logger.info(f"Amplitude range: [{np.nanmin(amplitude):.4f}, {np.nanmax(amplitude):.4f}]")
            logger.info(f"Phase range: [{np.nanmin(phase):.4f}, {np.nanmax(phase):.4f}]")

            # Check for valid data
            valid_amp = np.sum(~np.isnan(amplitude) & (amplitude > 0))
            valid_phase = np.sum(~np.isnan(phase))
            logger.info(f"Valid data points: amplitude={valid_amp}, phase={valid_phase}")

            if valid_amp == 0:
                raise RuntimeError(f"No valid amplitude data for {constituent} {variable}")

            # Create figure with simplified approach
            fig, ax = self.create_figure(ax=ax, use_cartopy=False, **kwargs)

            # Plot amplitude as simple contour/pcolormesh
            try:
                # Mask invalid data
                amplitude_masked = np.ma.masked_where(amplitude <= 0, amplitude)

                if len(lon_grid.shape) == 1 and len(lat_grid.shape) == 1:
                    # Regular grid - create meshgrid
                    lon_mesh, lat_mesh = np.meshgrid(lon_grid, lat_grid)
                    im = ax.pcolormesh(lon_mesh, lat_mesh, amplitude_masked, cmap='viridis', shading='nearest')
                else:
                    # Irregular grid
                    im = ax.pcolormesh(lon_grid, lat_grid, amplitude_masked, cmap='viridis', shading='nearest')

                # Add colorbar
                cbar = plt.colorbar(im, ax=ax, shrink=0.8)
                cbar.set_label(f'{constituent.upper()} {variable.replace("_", " ").title()} Amplitude ({units})')

                ax.set_xlabel('Longitude')
                ax.set_ylabel('Latitude')
                ax.set_title(f'{constituent.upper()} {variable.replace("_", " ").title()} Amplitude')

                # Set reasonable axis limits
                lon_min, lon_max = np.nanmin(lon_grid), np.nanmax(lon_grid)
                lat_min, lat_max = np.nanmin(lat_grid), np.nanmax(lat_grid)
                ax.set_xlim(lon_min, lon_max)
                ax.set_ylim(lat_min, lat_max)

                logger.info("Successfully created amplitude/phase map")

            except Exception as e:
                logger.error(f"Error creating amplitude/phase plot: {e}")
                raise RuntimeError(f"Error creating amplitude/phase plot: {str(e)}")

            ds.close()
            return self.finalize_plot(fig, ax, title=f'{constituent.upper()} {variable.replace("_", " ").title()}')

        except Exception as e:
            logger.error(f"Error plotting tidal amplitude/phase maps: {e}")
            raise RuntimeError(f"Error plotting tidal amplitude/phase maps: {str(e)}")

    def _parse_bctides_file(self, bctides_file: Path) -> dict:
        """Parse bctides.in file to extract boundary data."""
        try:
            with open(bctides_file, 'r') as f:
                lines = f.readlines()

            data = {
                'constituents': [],
                'boundaries': [],
                'start_time': None,
                'time_step': None
            }

            line_idx = 0
            while line_idx < len(lines):
                line = lines[line_idx].strip()
                if not line or line.startswith('!'):
                    line_idx += 1
                    continue

                parts = line.split()
                if len(parts) >= 1:
                    try:
                        value = float(parts[0])
                        if line_idx < 10:  # Header section
                            if line_idx == 0:
                                data['start_time'] = value
                            elif line_idx == 1:
                                data['time_step'] = value
                            elif line_idx == 2:
                                n_constituents = int(value)
                                # Read constituent names/frequencies
                                for i in range(n_constituents):
                                    line_idx += 1
                                    if line_idx < len(lines):
                                        const_line = lines[line_idx].strip()
                                        if const_line:
                                            try:
                                                const_value = const_line.split()[0]
                                                # Map frequency to constituent name
                                                const_name = self._frequency_to_constituent_name(const_value)
                                                data['constituents'].append(const_name)
                                            except (IndexError, ValueError):
                                                continue
                    except ValueError:
                        pass

                line_idx += 1

            return data

        except Exception as e:
            logger.warning(f"Error parsing bctides.in file: {e}")
            return {}

    def _plot_boundary_elevation_timeseries(self, ax: Axes, boundary_data: dict, times: np.ndarray):
        """Plot elevation time series from boundary data."""
        import numpy as np

        if not boundary_data.get('constituents'):
            raise RuntimeError("No constituent data available for boundary elevation time series plot")

        # Real implementation required: must use actual harmonic coefficients and boundary node data
        raise RuntimeError("Boundary elevation time series plotting requires real harmonic coefficients and boundary node data. Synthetic/demo data is not permitted.")

    def _plot_boundary_velocity_timeseries(self, ax: Axes, boundary_data: dict, times: np.ndarray):
        """Plot velocity time series from boundary data."""
        import numpy as np

        if not boundary_data.get('constituents'):
            raise RuntimeError("No constituent data available for boundary velocity time series plot")

        # Real implementation required: must use actual harmonic coefficients and boundary node data
        raise RuntimeError("Boundary velocity time series plotting requires real harmonic coefficients and boundary node data. Synthetic/demo data is not permitted.")

        # No plot is returned if error is raised above.

    def _plot_boundary_data_summary(self, ax: Axes, boundary_data: dict):
        """Plot summary of boundary data configuration."""
        summary_text = []

        if boundary_data.get('start_time') is not None:
            summary_text.append(f"Start Time: {boundary_data['start_time']}")

        if boundary_data.get('time_step') is not None:
            summary_text.append(f"Time Step: {boundary_data['time_step']} s")

        if boundary_data.get('constituents'):
            summary_text.append(f"Constituents ({len(boundary_data['constituents'])}):")
            for const in boundary_data['constituents']:
                summary_text.append(f"  • {const}")

        if boundary_data.get('boundaries'):
            summary_text.append(f"Boundary Segments: {len(boundary_data['boundaries'])}")

        if summary_text:
            ax.text(0.1, 0.9, '\n'.join(summary_text), transform=ax.transAxes,
                   verticalalignment='top', fontsize=11, fontfamily='monospace',
                   bbox=dict(boxstyle="round,pad=0.5", facecolor="lightyellow", alpha=0.8))
        else:
            raise RuntimeError("No boundary data summary available")

        ax.set_xlim(0, 1)
        ax.set_ylim(0, 1)
        ax.set_xticks([])
        ax.set_yticks([])

    def _plot_boundary_spatial(
        self,
        ds: xr.Dataset,
        variable: str,
        time_idx: int,
        level_idx: int,
        ax: Optional[Axes],
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """Plot spatial distribution of boundary data."""
        fig, ax = self.create_figure(ax=ax, **kwargs)

        # Filter out figure-related kwargs that shouldn't go to plotting functions
        plot_kwargs = {k: v for k, v in kwargs.items()
                      if k not in ['figsize', 'dpi', 'save_path', 'use_cartopy']}

        try:
            # Handle SCHISM boundary files (*.th.nc) which use time_series variable
            if 'time_series' in ds.data_vars:
                data_var = ds['time_series']

                # Extract data for specified time and level
                if 'time' in data_var.dims:
                    data = data_var.isel(time=time_idx)
                else:
                    data = data_var

                # Handle multi-dimensional data (levels, components)
                if len(data.shape) > 1:
                    if 'nLevels' in data.dims and data.sizes['nLevels'] > level_idx:
                        data = data.isel(nLevels=level_idx)
                    if 'nComponents' in data.dims:
                        data = data.isel(nComponents=0)  # Take first component

                # For boundary data, we need actual coordinates
                if 'nOpenBndNodes' in data.dims:
                    n_nodes = data.sizes['nOpenBndNodes']
                    values = data.values.flatten() if data.values.ndim > 1 else data.values

                    if self.grid:
                        # Get actual boundary coordinates from grid
                        try:
                            hgrid = self.grid.pylibs_hgrid

                            # Compute boundaries to get boundary node indices
                            if hasattr(hgrid, 'compute_bnd') and callable(getattr(hgrid, 'compute_bnd', None)):
                                hgrid.compute_bnd()
                            else:
                                raise RuntimeError("Grid object missing compute_bnd method")

                            boundary_nodes = getattr(hgrid, 'iobn', None)
                            if boundary_nodes is None or len(boundary_nodes) == 0:
                                raise ValueError("No open boundary information found in grid")

                            boundary_node_indices = boundary_nodes[0]
                            hgrid_x = getattr(hgrid, 'x', None)
                            hgrid_y = getattr(hgrid, 'y', None)
                            if hgrid_x is None or hgrid_y is None:
                                raise RuntimeError("Grid missing x or y coordinates")

                            if len(boundary_node_indices) == n_nodes:
                                # Get actual coordinates for boundary nodes
                                boundary_x = hgrid_x[boundary_node_indices]
                                boundary_y = hgrid_y[boundary_node_indices]

                                # Create spatial scatter plot with boundary data
                                im = ax.scatter(boundary_x, boundary_y, c=values,
                                               cmap=self.plot_config.cmap, s=50, **plot_kwargs)

                                # Add colorbar
                                units = ds[variable].attrs.get("units", "") if variable in ds.attrs else ""
                                if not units and 'time_series' in ds.data_vars:
                                    units = ds['time_series'].attrs.get("units", "")
                                label = f"{variable} ({units})" if units else variable
                                cbar = self.add_colorbar(fig, ax, im, label=label)

                                # Set extent based on boundary coordinates
                                margin = 0.05  # 5% margin
                                x_range = boundary_x.max() - boundary_x.min()
                                y_range = boundary_y.max() - boundary_y.min()
                                ax.set_xlim(boundary_x.min() - margin * x_range,
                                           boundary_x.max() + margin * x_range)
                                ax.set_ylim(boundary_y.min() - margin * y_range,
                                           boundary_y.max() + margin * y_range)

                                ax.set_xlabel('Longitude')
                                ax.set_ylabel('Latitude')
                            else:
                                logger.error(f"Boundary node count mismatch: grid={len(boundary_node_indices)}, data={n_nodes}")
                                logger.error(f"Grid boundary indices: {boundary_node_indices}")
                                logger.error(f"Data shape: {values.shape}")
                                # Fallback: plot as many as possible
                                min_nodes = min(len(boundary_node_indices), n_nodes, len(values))
                                logger.warning(f"Plotting only the first {min_nodes} boundary nodes due to mismatch.")
                                boundary_x = hgrid_x[boundary_node_indices[:min_nodes]]
                                boundary_y = hgrid_y[boundary_node_indices[:min_nodes]]
                                plot_values = values[:min_nodes]
                                im = ax.scatter(boundary_x, boundary_y, c=plot_values,
                                               cmap=self.plot_config.cmap, s=50, **plot_kwargs)
                                units = ds[variable].attrs.get("units", "") if variable in ds.attrs else ""
                                if not units and 'time_series' in ds.data_vars:
                                    units = ds['time_series'].attrs.get("units", "")
                                label = f"{variable} ({units})" if units else variable
                                cbar = self.add_colorbar(fig, ax, im, label=label)
                                margin = 0.05
                                x_range = boundary_x.max() - boundary_x.min()
                                y_range = boundary_y.max() - boundary_y.min()
                                ax.set_xlim(boundary_x.min() - margin * x_range,
                                           boundary_x.max() + margin * x_range)
                                ax.set_ylim(boundary_y.min() - margin * y_range,
                                           boundary_y.max() + margin * y_range)
                                ax.set_xlabel('Longitude')
                                ax.set_ylabel('Latitude')




                        except Exception as e:
                            logger.error(f"Could not access grid for boundary plotting: {e}")
                            raise RuntimeError(f"Could not access grid for boundary plotting: {e}")
        except Exception as e:
            logger.error(f"Error in boundary spatial plotting: {e}")
            raise

        # Handle other variable types with spatial coordinates
        if 'time_series' not in ds.data_vars:
            var_data = ds[variable]

            # Extract data for specified time and level
            if "time" in var_data.dims:
                data = var_data.isel(time=time_idx)
            else:
                data = var_data

            if len(data.shape) > 1 and level_idx < data.shape[-1]:
                data = data.isel({data.dims[-1]: level_idx})

        # Try to find spatial coordinates
        if hasattr(data, 'lon') and hasattr(data, 'lat'):
            x, y = data.lon.values, data.lat.values
        elif 'lon' in ds.coords and 'lat' in ds.coords:
            x, y = ds.lon.values, ds.lat.values
        else:
            raise ValueError("No valid spatial coordinates found for boundary data plotting")

        # Create spatial plot
        im = ax.scatter(x, y, c=data.values, cmap=self.plot_config.cmap, **plot_kwargs)

        # Add colorbar
        units = ds[variable].attrs.get("units", "")
        label = f"{variable} ({units})" if units else variable
        cbar = self.add_colorbar(fig, ax, im, label=label)

        # Set extent
        extent = get_geographic_extent(x, y)
        ax.set_xlim(extent[0], extent[1])
        ax.set_ylim(extent[2], extent[3])

        return self.finalize_plot(fig, ax, title=f"{variable} (Boundary Data)")

    def _plot_boundary_timeseries(
        self,
        ds: xr.Dataset,
        variable: str,
        level_idx: int,
        ax: Optional[Axes],
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """Plot time series of boundary data."""
        fig, ax = self.create_figure(ax=ax, use_cartopy=False, **kwargs)

        # Get variable data
        var_data = ds[variable]

        if "time" not in var_data.dims:
            raise ValueError(f"Variable {variable} does not have time dimension")

        # Average over nodes or select first node
        if "node" in var_data.dims:
            data = var_data.mean(dim="node")
        else:
            data = var_data

        # Handle vertical levels
        if len(data.shape) > 1 and level_idx < data.shape[-1]:
            data = data.isel({data.dims[-1]: level_idx})

        # Plot time series
        times = ds["time"].values
        ax.plot(times, data.values, **kwargs)

        # Set labels
        units = ds[variable].attrs.get("units", "")
        ylabel = f"{variable} ({units})" if units else variable
        ax.set_ylabel(ylabel)
        ax.set_xlabel("Time")

        # Format dates
        fig.autofmt_xdate()

        return self.finalize_plot(fig, ax, title=f"{variable} (Time Series)")

    def _plot_boundary_profile(
        self,
        ds: xr.Dataset,
        variable: str,
        time_idx: int,
        ax: Optional[Axes],
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """Plot vertical profile of boundary data."""
        fig, ax = self.create_figure(ax=ax, use_cartopy=False, **kwargs)

        var_data = ds[variable]

        # Find depth/level dimension
        depth_dim = None
        for dim in var_data.dims:
            if dim in ["depth", "level", "sigma", "z"]:
                depth_dim = dim
                break

        if depth_dim is None:
            raise ValueError(f"Variable {variable} does not have depth dimension")

        # Extract data for specified time
        if "time" in var_data.dims:
            data = var_data.isel(time=time_idx)
        else:
            data = var_data

        # Average over nodes
        if "node" in data.dims:
            data = data.mean(dim="node")

        # Get depth values
        depths = ds[depth_dim].values

        # Plot profile
        ax.plot(data.values, depths, **kwargs)

        # Invert y-axis for depth
        ax.invert_yaxis()

        # Set labels
        units = ds[variable].attrs.get("units", "")
        xlabel = f"{variable} ({units})" if units else variable
        ax.set_xlabel(xlabel)
        ax.set_ylabel(f"Depth ({ds[depth_dim].attrs.get('units', 'm')})")

        return self.finalize_plot(fig, ax, title=f"{variable} (Profile)")

    def _plot_velocity_magnitude(
        self,
        ds: xr.Dataset,
        u_var: str,
        v_var: str,
        time_idx: int,
        level_idx: int,
        ax: Optional[Axes],
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """Plot velocity magnitude."""
        fig, ax = self.create_figure(ax=ax, **kwargs)

        # Get velocity components
        u_data = ds[u_var][time_idx].values
        v_data = ds[v_var][time_idx].values

        # Handle 3D data
        if len(u_data.shape) > 1:
            u_data = u_data[level_idx]
            v_data = v_data[level_idx]

        # Calculate magnitude
        magnitude = np.sqrt(u_data**2 + v_data**2)

        # Plot using grid coordinates if available
        if self.grid:
            try:
                hgrid = self.grid.pylibs_hgrid
                x, y = hgrid.x, hgrid.y

                im = ax.scatter(x, y, c=magnitude, cmap=self.plot_config.cmap, **kwargs)

                # Add colorbar
                cbar = self.add_colorbar(fig, ax, im, label="Velocity Magnitude (m/s)")

                # Set extent
                extent = get_geographic_extent(x, y)
                ax.set_xlim(extent[0], extent[1])
                ax.set_ylim(extent[2], extent[3])

            except Exception as e:
                logger.error(f"Error plotting velocity magnitude: {e}")
                raise

        return self.finalize_plot(fig, ax, title="Velocity Magnitude")

    def _plot_velocity_vectors(
        self,
        ds: xr.Dataset,
        u_var: str,
        v_var: str,
        time_idx: int,
        level_idx: int,
        ax: Optional[Axes],
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """Plot velocity vectors."""
        fig, ax = self.create_figure(ax=ax, **kwargs)

        # Get velocity components
        u_data = ds[u_var][time_idx].values
        v_data = ds[v_var][time_idx].values

        # Handle 3D data
        if len(u_data.shape) > 1:
            u_data = u_data[level_idx]
            v_data = v_data[level_idx]

        # Plot using grid coordinates if available
        if self.grid:
            try:
                hgrid = self.grid.pylibs_hgrid
                x, y = hgrid.x, hgrid.y

                # Subsample for clearer visualization
                stride = kwargs.pop("stride", 5)
                scale = kwargs.pop("scale", None)

                q = ax.quiver(
                    x[::stride], y[::stride],
                    u_data[::stride], v_data[::stride],
                    scale=scale, **kwargs
                )

                # Add quiver key
                if scale:
                    ax.quiverkey(q, 0.9, 0.9, 1.0, "1 m/s", labelpos="E")

                # Set extent
                extent = get_geographic_extent(x, y)
                ax.set_xlim(extent[0], extent[1])
                ax.set_ylim(extent[2], extent[3])

            except Exception as e:
                logger.error(f"Error plotting velocity vectors: {e}")
                raise

        return self.finalize_plot(fig, ax, title="Velocity Vectors")

    def _plot_atmospheric_wind_vectors(
        self,
        ds: xr.Dataset,
        time_idx: int,
        level_idx: int,
        ax: Axes,
        fig: Figure,
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot atmospheric wind vectors.

        Parameters
        ----------
        ds : xr.Dataset
            Dataset containing wind data
        time_idx : int
            Time index
        level_idx : int
            Level index
        ax : Axes
            Axes object
        fig : Figure
            Figure object
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        # Get wind component names - check for ERA5 names first
        uwind_name = kwargs.pop("uwind_name", None)
        vwind_name = kwargs.pop("vwind_name", None)
        plot_type = kwargs.pop("plot_type", "quiver")

        # Auto-detect wind variable names if not specified
        if uwind_name is None:
            if "u10" in ds:
                uwind_name = "u10"
            elif "uwind" in ds:
                uwind_name = "uwind"
            else:
                raise ValueError("No U-wind component found in dataset (looked for 'u10' and 'uwind')")

        if vwind_name is None:
            if "v10" in ds:
                vwind_name = "v10"
            elif "vwind" in ds:
                vwind_name = "vwind"
            else:
                raise ValueError("No V-wind component found in dataset (looked for 'v10' and 'vwind')")

        if uwind_name not in ds or vwind_name not in ds:
            raise ValueError(
                f"Wind components {uwind_name} and {vwind_name} not found in dataset"
            )

        # Get coordinates
        lons = ds["lon"].values if "lon" in ds else ds["longitude"].values
        lats = ds["lat"].values if "lat" in ds else ds["latitude"].values

        # Get wind data for specified time and level
        u_data = ds[uwind_name][time_idx].values
        v_data = ds[vwind_name][time_idx].values

        # Handle 3D data
        if len(u_data.shape) > 2:
            u_data = u_data[level_idx]
            v_data = v_data[level_idx]

        # Create meshgrid if needed
        if len(lons.shape) == 1 and len(lats.shape) == 1:
            lons, lats = np.meshgrid(lons, lats)

        # Subsample for clearer visualization
        density = kwargs.pop("vector_density", 1)
        scale = kwargs.pop("vector_scale", None)

        # Filter out figure-related kwargs that shouldn't go to quiver/barbs
        vector_kwargs = {k: v for k, v in kwargs.items()
                        if k not in ['figsize', 'dpi', 'save_path', 'use_cartopy']}

        # Plot wind vectors
        if plot_type == "quiver":
            q = ax.quiver(
                lons[::density, ::density],
                lats[::density, ::density],
                u_data[::density, ::density],
                v_data[::density, ::density],
                scale=scale,
                **vector_kwargs,
            )
            # Add quiver key if scale is provided
            if scale:
                ax.quiverkey(q, 0.9, 0.9, 10, "10 m/s", labelpos="E")

        elif plot_type == "barbs":
            barb_length = kwargs.pop("barb_length", 5)
            barb_density = kwargs.pop("barb_density", 1)
            ax.barbs(
                lons[::barb_density, ::barb_density],
                lats[::barb_density, ::barb_density],
                u_data[::barb_density, ::barb_density],
                v_data[::barb_density, ::barb_density],
                length=barb_length,
                **vector_kwargs,
            )
        else:
            raise ValueError(f"Unsupported plot_type: {plot_type}")

        # Add grid boundaries if available
        if hasattr(self, 'grid') and self.grid is not None:
            try:
                add_boundary_overlay(ax, self.grid)
            except Exception as e:
                logger.warning(f"Could not add grid boundaries: {e}")

        # Set extent
        extent = get_geographic_extent(lons, lats)
        ax.set_xlim(extent[0], extent[1])
        ax.set_ylim(extent[2], extent[3])

        # Set title
        try:
            time_str = str(ds["time"].values[time_idx])
            title = f"Wind Vectors - {time_str}"
        except:
            title = "Wind Vectors"

        return self.finalize_plot(fig, ax, title=title)

    def _plot_atmospheric_wind_speed_timeseries(
        self,
        ds: xr.Dataset,
        lat: Optional[float],
        lon: Optional[float],
        location_idx: Optional[int],
        level_idx: int,
        ax: Optional[Axes],
        fig: Figure,
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot wind speed time series at a specific location.

        Parameters
        ----------
        ds : xr.Dataset
            Dataset containing wind data
        lat : Optional[float]
            Latitude of point to extract
        lon : Optional[float]
            Longitude of point to extract
        location_idx : Optional[int]
            Index of location to plot
        level_idx : int
            Vertical level index
        ax : Optional[Axes]
            Existing axes to plot on
        fig : Figure
            Figure object
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        # Get wind component names
        uwind_name = kwargs.pop("uwind_name", "uwind")
        vwind_name = kwargs.pop("vwind_name", "vwind")

        if uwind_name not in ds or vwind_name not in ds:
            raise ValueError(
                f"Wind components {uwind_name} and {vwind_name} not found in dataset"
            )

        # Get coordinates
        lons = ds["lon"].values if "lon" in ds else ds["longitude"].values
        lats = ds["lat"].values if "lat" in ds else ds["latitude"].values

        # Find location index
        if location_idx is None:
            if lat is None or lon is None:
                raise ValueError("Either location_idx or both lat and lon must be provided")

            if len(lons.shape) == 1 and len(lats.shape) == 1:
                lon_idx = np.abs(lons - lon).argmin()
                lat_idx = np.abs(lats - lat).argmin()
                location_idx = (lat_idx, lon_idx)
            else:
                points = np.vstack((lons.flatten(), lats.flatten())).T
                tree = cKDTree(points)
                _, location_idx = tree.query([lon, lat])

        # Extract time series for wind components
        times = ds["time"].values

        if isinstance(location_idx, tuple):
            u_values = ds[uwind_name].isel(
                {ds[uwind_name].dims[1]: location_idx[0],
                 ds[uwind_name].dims[2]: location_idx[1]}
            ).values
            v_values = ds[vwind_name].isel(
                {ds[vwind_name].dims[1]: location_idx[0],
                 ds[vwind_name].dims[2]: location_idx[1]}
            ).values
        else:
            # Handle flattened index
            u_values = ds[uwind_name].values.reshape(len(times), -1)[:, location_idx]
            v_values = ds[vwind_name].values.reshape(len(times), -1)[:, location_idx]

        # Handle 3D data
        if len(u_values.shape) > 1:
            u_values = u_values[:, level_idx]
            v_values = v_values[:, level_idx]

        # Compute wind speed
        wind_speed = np.sqrt(u_values**2 + v_values**2)

        # Plot time series
        ax.plot(times, wind_speed, **kwargs)

        # Set labels
        units = ds[uwind_name].attrs.get("units", "m/s")
        ylabel = f"Wind Speed ({units})" if units else "Wind Speed"
        ax.set_ylabel(ylabel)
        ax.set_xlabel("Time")

        # Format dates
        fig.autofmt_xdate()

        # Set title
        if isinstance(location_idx, tuple):
            if len(lons.shape) == 1 and len(lats.shape) == 1:
                loc_lat = lats[location_idx[0]]
                loc_lon = lons[location_idx[1]]
            else:
                loc_lat = lats[location_idx[0], location_idx[1]]
                loc_lon = lons[location_idx[0], location_idx[1]]
        else:
            loc_lat = lats.flatten()[location_idx]
            loc_lon = lons.flatten()[location_idx]

        title = f"Wind Speed at ({loc_lat:.2f}°, {loc_lon:.2f}°)"

        return self.finalize_plot(fig, ax, title=title)

    def plot_gr3_file(
        self,
        file_path: Union[str, Path],
        ax: Optional[Axes] = None,
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot .gr3 property files with appropriate colormaps.

        Parameters
        ----------
        file_path : Union[str, Path]
            Path to .gr3 file
        ax : Optional[Axes]
            Existing axes to plot on
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        from .utils import load_schism_data

        fig, ax = self.create_figure(ax=ax, **kwargs)

        # Load .gr3 file (assuming it can be loaded as grid with values)
        try:
            # Try to load using pyschism if available
            if hasattr(self, 'grid') and self.grid is not None:
                grid = self.grid
                if hasattr(grid, 'pylibs_hgrid'):
                    hgrid = grid.pylibs_hgrid
                    x = getattr(hgrid, 'x', None)
                    y = getattr(hgrid, 'y', None)
                    if x is None or y is None:
                        raise RuntimeError("Grid missing x or y coordinates")

                    # Read .gr3 file values
                    with open(file_path, 'r') as f:
                        lines = f.readlines()

                    # Skip header and node/element counts
                    data_lines = lines[2:]  # Skip first 2 lines (header + counts)

                    # Extract node values
                    values = []
                    for line in data_lines:
                        if line.strip():
                            parts = line.strip().split()
                            if len(parts) >= 4:  # node_id, x, y, value
                                values.append(float(parts[3]))

                    values = np.array(values)

                    # Determine colormap based on filename
                    file_name = Path(file_path).name.lower()
                    if 'bathy' in file_name or 'depth' in file_name:
                        cmap = 'viridis_r'  # Deeper = darker
                        label = 'Depth (m)'
                    elif 'rough' in file_name:
                        cmap = 'plasma'
                        label = 'Roughness'
                    elif 'temp' in file_name:
                        cmap = 'coolwarm'
                        label = 'Temperature (°C)'
                    elif 'sal' in file_name:
                        cmap = 'viridis'
                        label = 'Salinity'
                    else:
                        cmap = 'viridis'
                        label = 'Value'

                    # Create scatter plot
                    im = ax.scatter(x, y, c=values, cmap=cmap, s=1, **kwargs)

                    # Add colorbar
                    cbar = self.add_colorbar(fig, ax, im, label=label)

                    # Set title
                    title = f"{Path(file_path).name} Properties"
                else:
                    raise ValueError("Grid does not have pylibs_hgrid attribute")
            else:
                raise ValueError("No grid available for .gr3 plotting")

        except Exception as e:
            logger.error(f"Error plotting .gr3 file: {e}")
            # Fallback to simple text display
            logger.error(f"Error loading .gr3 file: {e}")
            raise RuntimeError(f"Error loading .gr3 file: {e}") # Do not plot error on figure

        return self.finalize_plot(fig, ax, title=title)

    def plot_bctides_file(
        self,
        file_path: Union[str, Path],
        ax: Optional[Axes] = None,
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot bctides.in configuration file.

        Parameters
        ----------
        file_path : Union[str, Path]
            Path to bctides.in file
        ax : Optional[Axes]
            Existing axes to plot on
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        fig, ax = self.create_figure(ax=ax, use_cartopy=False, **kwargs)

        try:
            # Read bctides.in file
            with open(file_path, 'r') as f:
                lines = f.readlines()

            # Parse basic information
            info_text = []
            constituent_count = 0
            boundary_count = 0

            for i, line in enumerate(lines):
                line = line.strip()
                if not line or line.startswith('!'):
                    continue

                if i < 10:  # First few lines contain configuration
                    parts = line.split()
                    if len(parts) >= 1:
                        try:
                            value = float(parts[0])
                            if i == 0:
                                info_text.append(f"Start time: {value}")
                            elif i == 1:
                                info_text.append(f"Time step: {value}")
                            elif i == 2:
                                constituent_count = int(value)
                                info_text.append(f"Constituents: {constituent_count}")
                        except ValueError:
                            if 'M2' in line or 'S2' in line or 'K1' in line or 'O1' in line:
                                info_text.append(f"Tidal constituent: {line}")

            # Display information as text
            y_pos = 0.9
            for text in info_text:
                ax.text(0.1, y_pos, text, transform=ax.transAxes, fontsize=12)
                y_pos -= 0.1

            # Add summary
            if boundary_count > 0:
                ax.text(0.1, y_pos-0.1, f"Boundary segments: {boundary_count}",
                       transform=ax.transAxes, fontsize=12, weight='bold')

            ax.set_xlim(0, 1)
            ax.set_ylim(0, 1)
            ax.set_xticks([])
            ax.set_yticks([])

            title = f"{Path(file_path).name} Configuration"

        except Exception as e:
            logger.error(f"Error parsing bctides.in file: {e}")
            logger.error(f"Error reading bctides.in: {e}")
            raise RuntimeError(f"Error reading bctides.in: {e}")

        return self.finalize_plot(fig, ax, title=title)

    def _get_atmospheric_dataset(self, variable: str) -> xr.Dataset:
        """Get atmospheric dataset from configuration."""
        if not self.config:
            raise ValueError("No configuration available for atmospheric data")

        if not hasattr(self.config, 'data') or not hasattr(self.config.data, 'atmos'):
            raise ValueError("No atmospheric data available in configuration")

        # Get dataset based on variable type
        if variable == "air":
            if hasattr(self.config.data.atmos, "air_1") and self.config.data.atmos.air_1:
                source = self.config.data.atmos.air_1.source
                if hasattr(source, 'dataset'):
                    return source.dataset
                elif hasattr(source, 'get_dataset'):
                    return source.get_dataset()
                elif hasattr(source, 'data'):
                    return source.data
                else:
                    # Load from file if it's a SourceFile
                    import xarray as xr
                    return xr.open_dataset(source.uri)
            elif hasattr(self.config.data.atmos, "air") and self.config.data.atmos.air:
                source = self.config.data.atmos.air.source
                if hasattr(source, 'dataset'):
                    return source.dataset
                elif hasattr(source, 'get_dataset'):
                    return source.get_dataset()
                elif hasattr(source, 'data'):
                    return source.data
                else:
                    import xarray as xr
                    return xr.open_dataset(source.uri)
        elif variable == "rad":
            if hasattr(self.config.data.atmos, "rad_1") and self.config.data.atmos.rad_1:
                source = self.config.data.atmos.rad_1.source
                if hasattr(source, 'dataset'):
                    return source.dataset
                elif hasattr(source, 'get_dataset'):
                    return source.get_dataset()
                elif hasattr(source, 'data'):
                    return source.data
                else:
                    import xarray as xr
                    return xr.open_dataset(source.uri)
        elif variable == "prc":
            if hasattr(self.config.data.atmos, "prc_1") and self.config.data.atmos.prc_1:
                source = self.config.data.atmos.prc_1.source
                if hasattr(source, 'dataset'):
                    return source.dataset
                elif hasattr(source, 'get_dataset'):
                    return source.get_dataset()
                elif hasattr(source, 'data'):
                    return source.data
                else:
                    import xarray as xr
                    return xr.open_dataset(source.uri)

        raise ValueError(f"No {variable} data available in configuration")

    def plot_atmospheric_inputs_at_points(
        self,
        sample_points: Optional[List[Tuple[float, float]]] = None,
        n_points: int = 4,
        time_hours: float = 24.0,
        ax: Optional[Axes] = None,
        plot_type: str = "wind_speed",
        variable: str = "air",
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot atmospheric inputs time series at sample grid points.

        Parameters
        ----------
        sample_points : Optional[List[Tuple[float, float]]]
            List of (lon, lat) coordinates for sample points. If None, representative
            points are automatically selected from grid interior.
        n_points : int, optional
            Number of sample points to use if sample_points is None. Default is 4.
        time_hours : float, optional
            Duration in hours for the time series. Default is 24.0 hours.
        ax : Optional[Axes]
            Existing axes to plot on
        plot_type : str, optional
            Type of plot: 'wind_speed', 'wind_u', 'wind_v', 'pressure', 'temperature'.
            Default is 'wind_speed'.
        variable : str, optional
            Atmospheric variable type: 'air', 'rad', 'prc'. Default is 'air'.
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        fig, ax = self.create_figure(ax=ax, use_cartopy=False, **kwargs)

        try:
            # Check if we have atmospheric data in config
            if not (self.config and hasattr(self.config, 'data') and
                    hasattr(self.config.data, 'atmos')):
                ax.text(0.5, 0.5, "No atmospheric data found in configuration",
                       ha='center', va='center', transform=ax.transAxes)
                return self.finalize_plot(fig, ax, title="Atmospheric Inputs - No Data")

            # Get atmospheric dataset
            ds = self._get_atmospheric_dataset(variable)

            # Get sample points
            if sample_points is None:
                sample_points = self._get_representative_atmospheric_points(n_points)

            if sample_points is None or len(sample_points) == 0:
                ax.text(0.5, 0.5, "No sample points available for atmospheric data",
                       ha='center', va='center', transform=ax.transAxes)
                return self.finalize_plot(fig, ax, title="Atmospheric Inputs - No Points")

            # Compute time series data
            time_series_data = self._compute_atmospheric_timeseries(
                ds, sample_points, plot_type, time_hours
            )

            # Create standardized time array
            dt = 0.5  # 30-minute intervals
            times = self._compute_standardized_time_axis(time_hours, dt)

            # Align data to standardized time axis if needed
            if len(time_series_data) > 0 and len(time_series_data[0]) != len(times):
                original_times = np.arange(0, len(time_series_data[0]) * dt, dt)
                aligned_data = []
                for data_series in time_series_data:
                    aligned_series = self._align_data_to_time_axis(data_series, original_times, times)
                    aligned_data.append(aligned_series)
                time_series_data = aligned_data

            # Plot time series for each point
            colors = plt.get_cmap('tab10')(np.linspace(0, 1, len(sample_points)))

            for i, ((lon, lat), color) in enumerate(zip(sample_points, colors)):
                if i < len(time_series_data):
                    ax.plot(times, time_series_data[i], color=color, linewidth=2,
                           label=f"Point {i+1} ({lon:.2f}°, {lat:.2f}°)")

            # Format plot
            ylabel = self._get_atmospheric_ylabel(plot_type)
            ax.set_xlabel("Time (hours)")
            ax.set_ylabel(ylabel)
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            ax.grid(True, alpha=0.3)

            # Add variable information
            var_text = f"Variable: {variable.upper()}\nParameter: {plot_type}"
            ax.text(0.02, 0.98, var_text, transform=ax.transAxes,
                   verticalalignment='top', fontsize=10,
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7))

        except Exception as e:
            logger.error(f"Error plotting atmospheric inputs: {e}")
            ax.text(0.5, 0.5, f"Error plotting atmospheric inputs:\n{str(e)}",
                   ha='center', va='center', transform=ax.transAxes,
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="lightcoral", alpha=0.7))
            ylabel = "Error"

        title_suffix = plot_type.replace('_', ' ').title()
        return self.finalize_plot(fig, ax, title=f"Atmospheric {title_suffix} at Sample Points")

    def plot_processed_atmospheric_data(
        self,
        sample_points: Optional[List[Tuple[float, float]]] = None,
        n_points: int = 4,
        time_hours: float = 24.0,
        ax: Optional[Axes] = None,
        plot_type: str = "wind_speed",
        variable: str = "air",
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot processed atmospheric data time series at sample grid points.
        This reads the actual sflux files generated by SCHISM.

        Parameters
        ----------
        sample_points : Optional[List[Tuple[float, float]]]
            List of (lon, lat) coordinates for sample points.
        n_points : int, optional
            Number of sample points to use if sample_points is None. Default is 4.
        time_hours : float, optional
            Duration in hours for the time series. Default is 24.0 hours.
        ax : Optional[Axes]
            Existing axes to plot on
        plot_type : str, optional
            Type of plot: 'wind_speed', 'wind_u', 'wind_v', 'pressure', 'temperature'.
        variable : str, optional
            Atmospheric variable type: 'air', 'rad', 'prc'. Default is 'air'.
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        fig, ax = self.create_figure(ax=ax, use_cartopy=False, **kwargs)

        try:
            # Look for processed sflux files
            sflux_files = self._find_sflux_files(variable)

            if not sflux_files:
                ax.text(0.5, 0.5, f"No processed sflux {variable} files found",
                       ha='center', va='center', transform=ax.transAxes)
                return self.finalize_plot(fig, ax, title="Processed Atmospheric - No Files")

            # Get sample points
            if sample_points is None:
                sample_points = self._get_representative_atmospheric_points(n_points)

            if sample_points is None or len(sample_points) == 0:
                ax.text(0.5, 0.5, "No sample points available",
                       ha='center', va='center', transform=ax.transAxes)
                return self.finalize_plot(fig, ax, title="Processed Atmospheric - No Points")

            # Load and process sflux data
            time_series_data = self._compute_processed_atmospheric_timeseries(
                sflux_files, sample_points, plot_type, time_hours
            )

            # Create standardized time array
            dt = 0.5  # 30-minute intervals
            times = self._compute_standardized_time_axis(time_hours, dt)

            # Align data to standardized time axis if needed
            if len(time_series_data) > 0 and len(time_series_data[0]) != len(times):
                original_times = np.arange(0, len(time_series_data[0]) * dt, dt)
                aligned_data = []
                for data_series in time_series_data:
                    aligned_series = self._align_data_to_time_axis(data_series, original_times, times)
                    aligned_data.append(aligned_series)
                time_series_data = aligned_data

            # Plot time series for each point
            colors = plt.get_cmap('tab10')(np.linspace(0, 1, len(sample_points)))

            for i, ((lon, lat), color) in enumerate(zip(sample_points, colors)):
                if i < len(time_series_data):
                    ax.plot(times, time_series_data[i], color=color, linewidth=2,
                           label=f"Point {i+1} ({lon:.2f}°, {lat:.2f}°)", alpha=0.8)

            # Format plot
            ylabel = self._get_atmospheric_ylabel(plot_type)
            ax.set_xlabel("Time (hours)")
            ax.set_ylabel(ylabel)
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
            ax.grid(True, alpha=0.3)

            # Add data source information
            source_text = f"Source: Processed sflux files\nVariable: {variable.upper()}\nParameter: {plot_type}"
            ax.text(0.02, 0.98, source_text, transform=ax.transAxes,
                   verticalalignment='top', fontsize=9,
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow", alpha=0.8))

        except Exception as e:
            logger.error(f"Error plotting processed atmospheric data: {e}")
            ax.text(0.5, 0.5, f"Error plotting processed data:\n{str(e)}",
                   ha='center', va='center', transform=ax.transAxes, fontsize=8,
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="lightcoral", alpha=0.7))

        title_suffix = plot_type.replace('_', ' ').title()
        return self.finalize_plot(fig, ax, title=f"Processed Atmospheric {title_suffix}")

    def _get_representative_atmospheric_points(self, n_points: int = 4) -> List[Tuple[float, float]]:
        """
        Get representative atmospheric sample points from the grid boundary nodes.
        This ensures points are on the actual boundary of the grid.

        Parameters
        ----------
        n_points : int
            Number of points to select

        Returns
        -------
        List[Tuple[float, float]]
            List of (lon, lat) coordinates
        """
        try:
            if not self.grid:
                raise RuntimeError("Grid object required for representative atmospheric points")

            hgrid = self.grid.pylibs_hgrid if hasattr(self.grid, 'pylibs_hgrid') else self.grid

            # Ensure boundaries are computed
            if not hasattr(hgrid, 'nob'):
                if getattr(hgrid, 'compute_bnd', None):
                    hgrid.compute_bnd()
                elif getattr(hgrid, 'compute_all', None):
                    hgrid.compute_all()

            # Get open boundary nodes
            boundary_nodes = getattr(hgrid, 'iobn', None)
            if boundary_nodes is not None and len(boundary_nodes) > 0:
                boundary_nodes = boundary_nodes[0]
                n_boundary = len(boundary_nodes)
                if n_boundary == 0:
                    raise RuntimeError("No boundary nodes found in grid")
                indices = np.linspace(0, n_boundary - 1, min(n_points, n_boundary), dtype=int)
                sample_points = []
                hgrid_x = getattr(hgrid, 'x', None)
                hgrid_y = getattr(hgrid, 'y', None)
                if hgrid_x is None or hgrid_y is None:
                    raise RuntimeError("Grid missing x or y coordinates")
                for idx in indices:
                    node_idx = int(boundary_nodes[idx])
                    if 0 <= node_idx < len(hgrid_x):
                        lon = float(hgrid_x[node_idx])
                        lat = float(hgrid_y[node_idx])
                        if not (np.isnan(lon) or np.isnan(lat) or np.isinf(lon) or np.isinf(lat)):
                            sample_points.append((lon, lat))
                if sample_points:
                    logger.info(f"Selected atmospheric sample points on grid boundary: {sample_points}")
                    return sample_points

            # If no boundary nodes found, fail immediately
            raise RuntimeError("No boundary nodes found in grid; cannot extract representative atmospheric points.")

        except Exception as e:
            logger.error(f"Error getting representative atmospheric points: {e}")
            return []

    def _get_grid_sample_points(self, n_points: int = 4) -> List[Tuple[float, float]]:
        """Fallback method to get sample points from grid bounds."""
        try:
            # Get grid bounds
            if not self.grid:
                return []

            # Get grid extent
            grid_obj = self.grid
            if hasattr(grid_obj, 'pylibs_hgrid'):
                x_coords = grid_obj.pylibs_hgrid.x
                y_coords = grid_obj.pylibs_hgrid.y
            else:
                # Fallback to grid data
                x_coords = grid_obj.hgrid.get_x()
                y_coords = grid_obj.hgrid.get_y()

            # Calculate domain bounds
            x_min, x_max = np.min(x_coords), np.max(x_coords)
            y_min, y_max = np.min(y_coords), np.max(y_coords)

            # Create sample points across the domain
            sample_points = []

            # Create a regular grid of sample points
            x_step = (x_max - x_min) / (n_points + 1)
            y_step = (y_max - y_min) / (n_points + 1)

            for i in range(1, n_points + 1):
                x = x_min + i * x_step
                y = y_min + i * y_step
                sample_points.append((x, y))

            return sample_points[:n_points]

        except Exception as e:
            logger.error(f"Error getting grid sample points: {e}")
            return []

    def _compute_atmospheric_timeseries(
        self,
        ds: xr.Dataset,
        sample_points: List[Tuple[float, float]],
        plot_type: str,
        time_hours: float
    ) -> List[np.ndarray]:
        """
        Compute atmospheric time series at sample points from input dataset.

        Parameters
        ----------
        ds : xr.Dataset
            Atmospheric dataset
        sample_points : List[Tuple[float, float]]
            Sample point coordinates
        plot_type : str
            Type of atmospheric variable to plot
        time_hours : float
            Duration in hours

        Returns
        -------
        List[np.ndarray]
            Time series data for each sample point
        """
        try:
            # Handle different coordinate formats (original vs sflux)
            coord_names = list(ds.coords.keys())
            dim_names = list(ds.dims.keys())

            # Check if this is sflux format (has ny_grid, nx_grid dimensions)
            is_sflux_format = 'ny_grid' in dim_names and 'nx_grid' in dim_names

            if is_sflux_format:
                # Sflux format: coordinates stored as data variables 'lon', 'lat'
                if 'lon' in ds.data_vars and 'lat' in ds.data_vars:
                    lons = ds['lon'].values
                    lats = ds['lat'].values
                    lon_coord = 'nx_grid'  # Use dimensions for indexing
                    lat_coord = 'ny_grid'
                else:
                    logger.error(f"Sflux format detected but no lon/lat data variables found")
                    return [np.zeros(int(time_hours * 2)) for _ in sample_points]
            else:
                # Original format: coordinates as coordinate arrays
                # Find longitude coordinate
                lon_coord = None
                for name in ['longitude', 'lon', 'x']:
                    if name in coord_names:
                        lon_coord = name
                        break

                # Find latitude coordinate
                lat_coord = None
                for name in ['latitude', 'lat', 'y']:
                    if name in coord_names:
                        lat_coord = name
                        break

                if not lon_coord or not lat_coord:
                    logger.error(f"Could not find lon/lat coordinates in {coord_names}")
                    return [np.zeros(int(time_hours * 2)) for _ in sample_points]

                lons = ds.coords[lon_coord].values
                lats = ds.coords[lat_coord].values

            # Get time subset - ensure we handle datetime indices properly
            if hasattr(ds.time, 'values'):
                time_values = ds.time.values
                if len(time_values) > 0:
                    n_times = min(int(time_hours * 2), len(time_values))  # 30-min intervals
                else:
                    n_times = int(time_hours * 2)
            else:
                n_times = min(int(time_hours * 2), len(ds.time))

            ds_subset = ds.isel(time=slice(0, n_times))

            time_series_data = []

            for lon, lat in sample_points:
                try:
                    # Convert coordinates to float64 to avoid datetime issues
                    lons_float = np.asarray(lons, dtype=np.float64)
                    lats_float = np.asarray(lats, dtype=np.float64)
                    lon_float = float(lon)
                    lat_float = float(lat)

                    # Find nearest grid point - handle points outside domain gracefully
                    if len(lons.shape) == 1:
                        # 1D coordinate arrays
                        lon_idx = np.abs(lons_float - lon_float).argmin()
                        lat_idx = np.abs(lats_float - lat_float).argmin()
                    else:
                        # Handle 2D coordinate arrays (including sflux format)
                        from scipy.spatial import cKDTree
                        points = np.column_stack([lons_float.ravel(), lats_float.ravel()])
                        tree = cKDTree(points)
                        distance, idx = tree.query([lon_float, lat_float])

                        # Check if point is too far from grid (> 2 degrees)
                        if distance > 2.0:
                            logger.warning(f"Point ({lon_float:.3f}, {lat_float:.3f}) is {distance:.2f} degrees from nearest atmospheric grid point")
                            time_series_data.append(np.zeros(n_times))
                            continue

                        # Convert to 2D indices - be careful with dimensions
                        if len(lons.shape) == 2:
                            lat_idx, lon_idx = np.unravel_index(idx, lons.shape)
                            # Ensure indices are within bounds
                            lat_idx = min(max(lat_idx, 0), lons.shape[0] - 1)
                            lon_idx = min(max(lon_idx, 0), lons.shape[1] - 1)
                        else:
                            # Handle 1D case - use proper bounds checking
                            if len(lons) > 0:
                                lon_idx = min(max(idx % len(lons), 0), len(lons) - 1)
                                lat_idx = min(max(idx // len(lons), 0), len(lats) - 1) if len(lats) > 0 else 0
                            else:
                                lon_idx, lat_idx = 0, 0

                    # Extract data based on plot type
                    if plot_type == "wind_speed":
                        # Calculate wind speed from u and v components
                        u_var = self._find_variable(ds_subset, ['uwind', 'u10', 'u'])
                        v_var = self._find_variable(ds_subset, ['vwind', 'v10', 'v'])

                        if u_var and v_var:
                            u_data = ds_subset[u_var].isel({lat_coord: lat_idx, lon_coord: lon_idx}).values
                            v_data = ds_subset[v_var].isel({lat_coord: lat_idx, lon_coord: lon_idx}).values
                            data = np.sqrt(u_data**2 + v_data**2)
                        else:
                            data = np.zeros(n_times)

                    elif plot_type == "wind_u":
                        u_var = self._find_variable(ds_subset, ['uwind', 'u10', 'u'])
                        data = ds_subset[u_var].isel({lat_coord: lat_idx, lon_coord: lon_idx}).values if u_var else np.zeros(n_times)

                    elif plot_type == "wind_v":
                        v_var = self._find_variable(ds_subset, ['vwind', 'v10', 'v'])
                        data = ds_subset[v_var].isel({lat_coord: lat_idx, lon_coord: lon_idx}).values if v_var else np.zeros(n_times)

                    elif plot_type == "pressure":
                        p_var = self._find_variable(ds_subset, ['prmsl', 'msl', 'pressure'])
                        data = ds_subset[p_var].isel({lat_coord: lat_idx, lon_coord: lon_idx}).values if p_var else np.zeros(n_times)

                    elif plot_type == "temperature":
                        t_var = self._find_variable(ds_subset, ['air_temperature', 't2m', 'temperature'])
                        data = ds_subset[t_var].isel({lat_coord: lat_idx, lon_coord: lon_idx}).values if t_var else np.zeros(n_times)

                    else:
                        # Default to first available variable
                        var_name = list(ds_subset.data_vars)[0]
                        data = ds_subset[var_name].isel({lat_coord: lat_idx, lon_coord: lon_idx}).values

                    time_series_data.append(data)

                except Exception as e:
                    logger.warning(f"Error processing point ({lon}, {lat}): {e}")
                    time_series_data.append(np.zeros(n_times))

            return time_series_data

        except Exception as e:
            logger.error(f"Error computing atmospheric time series: {e}")
            return [np.zeros(int(time_hours * 2)) for _ in sample_points]

    def _find_variable(self, ds: xr.Dataset, var_names: List[str]) -> Optional[str]:
        """Find the first available variable from a list of possible names."""
        for var_name in var_names:
            if var_name in ds.data_vars:
                return var_name
        return None

    def _find_sflux_files(self, variable: str) -> List[Path]:
        """Find processed sflux files for a given variable type."""
        try:
            # Look for sflux files starting with actual model output locations
            search_paths = [
                Path.cwd() / "sflux",
                Path.cwd(),
                Path.cwd() / "outputs" / "sflux",
                # Look in common demo output directories
                Path.cwd() / "schism_demo_output" / "model_run" / "*" / "sflux",
                Path.cwd() / "*" / "sflux"
            ]

            # If we have a config with output directory, look there
            if self.config and hasattr(self.config, 'output_dir'):
                config_output_dir = Path(self.config.output_dir)
                search_paths.extend([
                    config_output_dir / "sflux",
                    config_output_dir / "*" / "sflux"
                ])

            sflux_files = []
            found_paths = set()  # Track unique file paths to avoid duplicates

            for search_path in search_paths:
                try:
                    # Handle glob patterns in path
                    if "*" in str(search_path):
                        for actual_path in Path(".").glob(str(search_path.relative_to(Path.cwd()))):
                            if actual_path.exists() and actual_path.is_dir():
                                # Look for different file patterns based on variable
                                patterns = [
                                    f"sflux_{variable}_*.nc",  # Standard sflux format
                                    f"{variable}_*.nc",       # Alternative format (air_1.0001.nc)
                                    f"{variable}*.nc"         # General format
                                ]
                                for pattern in patterns:
                                    files = list(actual_path.glob(pattern))
                                    for f in files:
                                        if f not in found_paths:
                                            sflux_files.append(f)
                                            found_paths.add(f)
                    else:
                        if search_path.exists():
                            # Look for different file patterns based on variable
                            patterns = [
                                f"sflux_{variable}_*.nc",  # Standard sflux format
                                f"{variable}_*.nc",       # Alternative format (air_1.0001.nc)
                                f"{variable}*.nc"         # General format
                            ]
                            for pattern in patterns:
                                files = list(search_path.glob(pattern))
                                for f in files:
                                    if f not in found_paths:
                                        sflux_files.append(f)
                                        found_paths.add(f)
                except Exception as e:
                    logger.debug(f"Error searching path {search_path}: {e}")
                    continue

            # Return only the most recent/relevant files (first match per directory)
            unique_files = []
            seen_dirs = set()
            for f in sorted(sflux_files, reverse=True):  # Most recent first
                parent_dir = f.parent
                if parent_dir not in seen_dirs:
                    unique_files.append(f)
                    seen_dirs.add(parent_dir)

            return sorted(unique_files)

        except Exception as e:
            logger.error(f"Error finding sflux files: {e}")
            return []

    def _compute_processed_atmospheric_timeseries(
        self,
        sflux_files: List[Path],
        sample_points: List[Tuple[float, float]],
        plot_type: str,
        time_hours: float
    ) -> List[np.ndarray]:
        """
        Compute atmospheric time series from processed sflux files.
        Ensures consistent sampling with input data by using the same coordinate system.

        Parameters
        ----------
        sflux_files : List[Path]
            List of sflux file paths
        sample_points : List[Tuple[float, float]]
            Sample point coordinates (should match input data points)
        plot_type : str
            Type of atmospheric variable to plot
        time_hours : float
            Duration in hours

        Returns
        -------
        List[np.ndarray]
            Time series data for each sample point
        """
        try:
            import xarray as xr

            if not sflux_files:
                logger.warning("No sflux files provided for processed atmospheric data")
                return [np.zeros(int(time_hours * 2)) for _ in sample_points]

            # Use the first (most recent) sflux file
            file_path = sflux_files[0]
            logger.info(f"Loading processed sflux data from: {file_path}")

            try:
                ds = xr.open_dataset(file_path)
            except Exception as e:
                logger.error(f"Could not load {file_path}: {e}")
                return [np.zeros(int(time_hours * 2)) for _ in sample_points]

            # Get available time range (sflux files may have limited time coverage)
            available_times = len(ds.time) if 'time' in ds.dims else 1
            n_times = min(int(time_hours * 2), available_times)

            if n_times < int(time_hours * 2):
                logger.info(f"Sflux file has {available_times} time steps, requested {int(time_hours * 2)}")

            ds_subset = ds.isel(time=slice(0, n_times)) if 'time' in ds.dims else ds

            # Use the same atmospheric timeseries computation for consistency
            logger.info(f"Computing processed atmospheric timeseries for {len(sample_points)} points over {n_times} time steps")
            return self._compute_atmospheric_timeseries(ds_subset, sample_points, plot_type, time_hours)

        except Exception as e:
            logger.error(f"Error computing processed atmospheric time series: {e}")
            return [np.zeros(int(time_hours * 2)) for _ in sample_points]

    def _get_atmospheric_ylabel(self, plot_type: str) -> str:
        """Get appropriate y-axis label for atmospheric plot type."""
        ylabel_map = {
            "wind_speed": "Wind Speed (m/s)",
            "wind_u": "U Wind Component (m/s)",
            "wind_v": "V Wind Component (m/s)",
            "pressure": "Pressure (Pa)",
            "temperature": "Temperature (K)"
        }
        return ylabel_map.get(plot_type, plot_type.replace('_', ' ').title())

    def plot_ocean_boundary_inputs_at_points(
        self,
        sample_points: Optional[List[Tuple[float, float]]] = None,
        n_points: int = 4,
        time_hours: float = 24.0,
        ax: Optional[Axes] = None,
        plot_type: str = "elevation",
        boundary_type: str = "2d",
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot ocean boundary inputs time series at sample boundary points.

        Parameters
        ----------
        sample_points : Optional[List[Tuple[float, float]]]
            List of (lon, lat) coordinates for sample points. If None, representative
            boundary points are automatically selected.
        n_points : int, optional
            Number of sample points to use if sample_points is None. Default is 4.
        time_hours : float, optional
            Duration in hours for the time series. Default is 24.0 hours.
        ax : Optional[Axes]
            Existing axes to plot on
        plot_type : str, optional
            Type of plot: 'elevation', 'velocity_u', 'velocity_v', 'velocity_magnitude',
            'temperature', 'salinity'. Default is 'elevation'.
        boundary_type : str, optional
            Type of boundary: '2d' or '3d'. Default is '2d'.
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        fig, ax = self.create_figure(ax=ax, use_cartopy=False, **kwargs)

        try:
            # Check if we have ocean boundary data in config
            if not (self.config and hasattr(self.config, 'data') and
                    hasattr(self.config.data, 'boundary_conditions')):
                ax.text(0.5, 0.5, "No ocean boundary data found in configuration",
                       ha='center', va='center', transform=ax.transAxes)
                return self.finalize_plot(fig, ax, title="Ocean Boundary Inputs - No Data")

            bc = self.config.data.boundary_conditions

            # Get data sources from boundary conditions
            data_sources = self._get_ocean_boundary_sources(bc, plot_type, boundary_type)

            if not data_sources:
                ax.text(0.5, 0.5, f"No {plot_type} data sources found for {boundary_type} boundaries",
                       ha='center', va='center', transform=ax.transAxes)
                return self.finalize_plot(fig, ax, title="Ocean Boundary Inputs - No Sources")

            # Get sample points
            if sample_points is None:
                sample_points = self._get_representative_boundary_points(n_points)

            if sample_points is None or len(sample_points) == 0:
                ax.text(0.5, 0.5, "No boundary points available for sampling",
                       ha='center', va='center', transform=ax.transAxes)
                return self.finalize_plot(fig, ax, title="Ocean Boundary Inputs - No Points")

            # Compute time series data from input sources
            time_series_data = self._compute_ocean_boundary_input_timeseries(
                data_sources[0], sample_points, plot_type, time_hours
            )

            # Create standardized time array
            dt = 0.5  # 30-minute intervals
            times = self._compute_standardized_time_axis(time_hours, dt)

            # Align data to standardized time axis if needed
            if len(time_series_data) > 0 and len(time_series_data[0]) != len(times):
                original_times = np.arange(0, len(time_series_data[0]) * dt, dt)
                aligned_data = []
                for data_series in time_series_data:
                    aligned_series = self._align_data_to_time_axis(data_series, original_times, times)
                    aligned_data.append(aligned_series)
                time_series_data = aligned_data

            # Plot time series for each point
            colors = plt.get_cmap('tab10')(np.linspace(0, 1, len(sample_points)))

            for i, ((lon, lat), color) in enumerate(zip(sample_points, colors)):
                if i < len(time_series_data):
                    ax.plot(times, time_series_data[i], color=color, linewidth=2,
                           label=f"Point {i+1} ({lon:.2f}°, {lat:.2f}°)")

            # Format plot
            ylabel = self._get_ocean_boundary_ylabel(plot_type)
            ax.set_xlabel("Time (hours)")
            ax.set_ylabel(ylabel)
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            ax.grid(True, alpha=0.3)

            # Add variable information
            var_text = f"Type: {boundary_type.upper()}\nParameter: {plot_type}"
            ax.text(0.02, 0.98, var_text, transform=ax.transAxes,
                   verticalalignment='top', fontsize=10,
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7))

        except Exception as e:
            logger.error(f"Error plotting ocean boundary inputs: {e}")
            ax.text(0.5, 0.5, f"Error plotting ocean boundary inputs:\n{str(e)}",
                   ha='center', va='center', transform=ax.transAxes,
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="lightcoral", alpha=0.7))

        title_suffix = f"{boundary_type.upper()} {plot_type.replace('_', ' ').title()}"
        return self.finalize_plot(fig, ax, title=f"Ocean Boundary Input {title_suffix}")

    def plot_processed_ocean_boundary_data(
        self,
        sample_points: Optional[List[Tuple[float, float]]] = None,
        n_points: int = 4,
        time_hours: float = 24.0,
        ax: Optional[Axes] = None,
        plot_type: str = "elevation",
        boundary_type: str = "2d",
        **kwargs
    ) -> Tuple[Figure, Axes]:
        """
        Plot processed ocean boundary data time series at sample boundary points.
        This reads the actual SCHISM boundary files (*.th.nc).

        Parameters
        ----------
        sample_points : Optional[List[Tuple[float, float]]]
            List of (lon, lat) coordinates for sample points.
        n_points : int, optional
            Number of sample points to use if sample_points is None. Default is 4.
        time_hours : float, optional
            Duration in hours for the time series. Default is 24.0 hours.
        ax : Optional[Axes]
            Existing axes to plot on
        plot_type : str, optional
            Type of plot: 'elevation', 'velocity_u', 'velocity_v', 'velocity_magnitude',
            'temperature', 'salinity'.
        boundary_type : str, optional
            Type of boundary: '2d' or '3d'. Default is '2d'.
        **kwargs : dict
            Additional plotting parameters

        Returns
        -------
        fig : Figure
            Figure object
        ax : Axes
            Axes object
        """
        fig, ax = self.create_figure(ax=ax, use_cartopy=False, **kwargs)

        try:
            # Look for processed boundary files
            boundary_files = self._find_boundary_files(plot_type, boundary_type)

            if not boundary_files:
                # For tidal-only setups, use bctides.in data instead
                if (self.config and hasattr(self.config, 'data') and
                    hasattr(self.config.data, 'boundary_conditions') and
                    hasattr(self.config.data.boundary_conditions, 'setup_type') and
                    self.config.data.boundary_conditions.setup_type == 'tidal'):

                    # Look for bctides.in files
                    bctides_files = self._find_bctides_files()
                    if bctides_files:
                        ax.text(0.5, 0.5, f"Tidal-only setup: Boundary conditions computed on-the-fly\nfrom bctides.in during model execution.\nNo separate processed files generated.",
                               ha='center', va='center', transform=ax.transAxes,
                               bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen", alpha=0.7))
                        return self.finalize_plot(fig, ax, title="Processed Ocean Boundary - Tidal Setup")

                ax.text(0.5, 0.5, f"No processed {plot_type} boundary files found",
                       ha='center', va='center', transform=ax.transAxes)
                return self.finalize_plot(fig, ax, title="Processed Ocean Boundary - No Files")

            # Get sample points
            if sample_points is None:
                sample_points = self._get_representative_boundary_points(n_points)

            if sample_points is None or len(sample_points) == 0:
                ax.text(0.5, 0.5, "No boundary points available",
                       ha='center', va='center', transform=ax.transAxes)
                return self.finalize_plot(fig, ax, title="Processed Ocean Boundary - No Points")

            # Load and process boundary data
            time_series_data = self._compute_processed_boundary_timeseries(
                boundary_files[0], sample_points, plot_type, time_hours
            )

            # Create standardized time array
            dt = 0.5  # 30-minute intervals
            times = self._compute_standardized_time_axis(time_hours, dt)

            # Align data to standardized time axis if needed
            if len(time_series_data) > 0 and len(time_series_data[0]) != len(times):
                original_times = np.arange(0, len(time_series_data[0]) * dt, dt)
                aligned_data = []
                for data_series in time_series_data:
                    aligned_series = self._align_data_to_time_axis(data_series, original_times, times)
                    aligned_data.append(aligned_series)
                time_series_data = aligned_data

            # Plot time series for each point
            colors = plt.get_cmap('tab10')(np.linspace(0, 1, len(sample_points)))

            for i, ((lon, lat), color) in enumerate(zip(sample_points, colors)):
                if i < len(time_series_data):
                    ax.plot(times, time_series_data[i], color=color, linewidth=2,
                           label=f"Point {i+1} ({lon:.2f}°, {lat:.2f}°)", alpha=0.8)

            # Format plot
            ylabel = self._get_ocean_boundary_ylabel(plot_type)
            ax.set_xlabel("Time (hours)")
            ax.set_ylabel(ylabel)
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
            ax.grid(True, alpha=0.3)

            # Add data source information
            source_text = f"Source: Processed boundary files\nType: {boundary_type.upper()}\nParameter: {plot_type}"
            ax.text(0.02, 0.98, source_text, transform=ax.transAxes,
                   verticalalignment='top', fontsize=9,
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow", alpha=0.8))

        except Exception as e:
            logger.error(f"Error plotting processed ocean boundary data: {e}")
            ax.text(0.5, 0.5, f"Error plotting processed data:\n{str(e)}",
                   ha='center', va='center', transform=ax.transAxes, fontsize=8,
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="lightcoral", alpha=0.7))

        title_suffix = f"{boundary_type.upper()} {plot_type.replace('_', ' ').title()}"
        return self.finalize_plot(fig, ax, title=f"Processed Ocean Boundary {title_suffix}")

    def _get_ocean_boundary_sources(self, bc, plot_type: str, boundary_type: str) -> List:
        """Get ocean boundary data sources from boundary conditions configuration."""
        try:
            sources = []

            # Check for tidal data sources (most common case)
            if hasattr(bc, 'tidal_data') and bc.tidal_data:
                if plot_type == "elevation" and hasattr(bc.tidal_data, 'elevations'):
                    sources.append(bc.tidal_data.elevations)
                elif plot_type in ["velocity_u", "velocity_v", "velocity_magnitude"] and hasattr(bc.tidal_data, 'velocities'):
                    sources.append(bc.tidal_data.velocities)

            # Check each boundary configuration (for non-tidal setups)
            if hasattr(bc, 'boundaries') and bc.boundaries:
                for idx, setup in bc.boundaries.items():
                    if plot_type == "elevation":
                        if hasattr(setup, 'elev_source') and setup.elev_source:
                            sources.append(setup.elev_source)
                    elif plot_type in ["velocity_u", "velocity_v", "velocity_magnitude"]:
                        if hasattr(setup, 'vel_source') and setup.vel_source:
                            sources.append(setup.vel_source)
                    elif plot_type == "temperature":
                        if hasattr(setup, 'temp_source') and setup.temp_source:
                            sources.append(setup.temp_source)
                    elif plot_type == "salinity":
                        if hasattr(setup, 'salt_source') and setup.salt_source:
                            sources.append(setup.salt_source)

            return sources

        except Exception as e:
            logger.error(f"Error getting ocean boundary sources: {e}")
            return []

    def _find_boundary_files(self, plot_type: str, boundary_type: str) -> List[Path]:
        """Find processed boundary files for a given variable type."""
        try:
            # Map plot types to SCHISM file naming convention
            file_mapping = {
                "elevation": "elev2D.th.nc",
                "velocity_u": "uv3D.th.nc",
                "velocity_v": "uv3D.th.nc",
                "velocity_magnitude": "uv3D.th.nc",
                "temperature": "TEM_3D.th.nc",
                "salinity": "SAL_3D.th.nc"
            }

            filename = file_mapping.get(plot_type)
            if not filename:
                return []

            # Look for boundary files in SCHISM output locations
            search_paths = [
                Path.cwd(),
                Path.cwd() / "outputs",
                Path.cwd() / "boundary_data",
                Path.cwd() / "schism_demo_output" / "model_run" / "*"
            ]

            # If we have a config with output directory, look there
            if self.config and hasattr(self.config, 'output_dir'):
                config_output_dir = Path(self.config.output_dir)
                search_paths.extend([
                    config_output_dir,
                    config_output_dir / "outputs",
                    config_output_dir / "*"
                ])

            boundary_files = []
            for search_path in search_paths:
                try:
                    if "*" in str(search_path):
                        # Handle glob patterns
                        for actual_path in Path(".").glob(str(search_path.relative_to(Path.cwd()))):
                            if actual_path.exists() and actual_path.is_dir():
                                file_path = actual_path / filename
                                if file_path.exists():
                                    boundary_files.append(file_path)
                                    logger.info(f"Found boundary file: {file_path}")
                    else:
                        if search_path.exists():
                            file_path = search_path / filename
                            if file_path.exists():
                                boundary_files.append(file_path)
                                logger.info(f"Found boundary file: {file_path}")
                except Exception as e:
                    logger.debug(f"Error searching path {search_path}: {e}")
                    continue

            return boundary_files

        except Exception as e:
            logger.error(f"Error finding boundary files: {e}")
            return []

    def _find_bctides_files(self) -> List[Path]:
        """Find bctides.in files in the project."""
        try:
            search_paths = [
                Path.cwd(),
                Path.cwd() / "outputs",
                Path.cwd() / "schism_demo_output" / "model_run" / "*",
                Path.cwd() / "*"
            ]

            bctides_files = []
            for search_path in search_paths:
                try:
                    if "*" in str(search_path):
                        for actual_path in Path(".").glob(str(search_path.relative_to(Path.cwd()))):
                            if actual_path.exists() and actual_path.is_dir():
                                bctides_file = actual_path / "bctides.in"
                                if bctides_file.exists():
                                    bctides_files.append(bctides_file)
                    else:
                        if search_path.exists():
                            bctides_file = search_path / "bctides.in"
                            if bctides_file.exists():
                                bctides_files.append(bctides_file)
                except Exception as e:
                    logger.debug(f"Error searching path {search_path}: {e}")
                    continue

            return bctides_files

        except Exception as e:
            logger.error(f"Error finding bctides files: {e}")
            return []

    def _compute_ocean_boundary_input_timeseries(
        self,
        data_source,
        sample_points: List[Tuple[float, float]],
        plot_type: str,
        time_hours: float
    ) -> List[np.ndarray]:
        """
        Compute ocean boundary time series from input data source.
        For TPXO data, this generates synthetic time series from harmonic constants.

        Parameters
        ----------
        data_source
            Data source object or file path
        sample_points : List[Tuple[float, float]]
            Sample point coordinates
        plot_type : str
            Type of variable to plot
        time_hours : float
            Duration in hours

        Returns
        -------
        List[np.ndarray]
            Time series data for each sample point
        """
        try:
            import xarray as xr

            # Get dataset from source
            ds = None
            if isinstance(data_source, (str, Path)):
                # Direct file path (common for tidal data)
                ds = xr.open_dataset(data_source)
            elif hasattr(data_source, 'source'):
                source = data_source.source
                if hasattr(source, 'dataset'):
                    ds = source.dataset
                elif hasattr(source, 'get_dataset'):
                    ds = source.get_dataset()
                elif hasattr(source, 'data'):
                    ds = source.data
                elif hasattr(source, 'uri'):
                    ds = xr.open_dataset(source.uri)
            elif hasattr(data_source, 'uri'):
                ds = xr.open_dataset(data_source.uri)
            elif hasattr(data_source, 'dataset'):
                ds = data_source.dataset

            if ds is None:
                logger.warning(f"Could not load dataset from source: {data_source}")
                return [np.zeros(int(time_hours * 2)) for _ in sample_points]

            # Check if this is TPXO format (harmonic constants, no time dimension)
            is_tpxo_format = ('time' not in ds.dims and 'nc' in ds.dims and
                             any(var in ds.data_vars for var in ['ha', 'hp', 'hRe', 'hIm']))

            if is_tpxo_format:
                # Generate time series from TPXO harmonic constants
                return self._compute_tidal_timeseries_from_harmonics(ds, sample_points, plot_type, time_hours)
            else:
                # Handle regular time series data
                if 'time' in ds.dims:
                    n_times = min(int(time_hours * 2), len(ds.time))
                    ds_subset = ds.isel(time=slice(0, n_times))
                else:
                    logger.warning("No time dimension found in dataset")
                    n_times = int(time_hours * 2)
                    ds_subset = ds

                # Get variable names based on plot type
                var_names = self._get_ocean_variable_names(plot_type)

                time_series_data = []

                for lon, lat in sample_points:
                    try:
                        # For ocean boundary data, we need to handle interpolation differently
                        # Get coordinates from dataset
                        if 'lon_z' in ds_subset.data_vars and 'lat_z' in ds_subset.data_vars:
                            lons = ds_subset['lon_z'].values
                            lats = ds_subset['lat_z'].values
                        elif 'longitude' in ds_subset.coords:
                            lons = ds_subset.coords['longitude'].values
                            lats = ds_subset.coords['latitude'].values
                        else:
                            # Skip interpolation for this point
                            time_series_data.append(np.zeros(n_times))
                            continue

                        # Find nearest point
                        if len(lons.shape) == 2:
                            dist = np.sqrt((lons - lon)**2 + (lats - lat)**2)
                            min_idx = np.unravel_index(np.argmin(dist), dist.shape)
                        else:
                            lon_idx = np.abs(lons - lon).argmin()
                            lat_idx = np.abs(lats - lat).argmin()
                            min_idx = (lat_idx, lon_idx)

                        if plot_type == "velocity_magnitude":
                            # Calculate magnitude from u and v components
                            u_var = self._find_variable(ds_subset, ['u', 'vozocrtx', 'uo'])
                            v_var = self._find_variable(ds_subset, ['v', 'vomecrty', 'vo'])

                            if u_var and v_var:
                                u_data = ds_subset[u_var].values
                                v_data = ds_subset[v_var].values
                                if len(u_data.shape) > 2:  # 3D data
                                    u_point = u_data[:, min_idx[0], min_idx[1]]
                                    v_point = v_data[:, min_idx[0], min_idx[1]]
                                elif len(u_data.shape) == 2:  # 2D data
                                    u_point = u_data[min_idx[0], min_idx[1]]
                                    v_point = v_data[min_idx[0], min_idx[1]]
                                    if np.isscalar(u_point):
                                        u_point = np.full(n_times, u_point)
                                        v_point = np.full(n_times, v_point)
                                else:
                                    u_point = u_data
                                    v_point = v_data
                                data = np.sqrt(u_point**2 + v_point**2) if not np.isscalar(u_point) else np.full(n_times, np.sqrt(u_point**2 + v_point**2))
                            else:
                                data = np.zeros(n_times)

                        elif plot_type == "velocity_u":
                            u_var = self._find_variable(ds_subset, ['u', 'vozocrtx', 'uo'])
                            if u_var:
                                u_data = ds_subset[u_var].values
                                if len(u_data.shape) > 2:  # 3D data
                                    data = u_data[:, min_idx[0], min_idx[1]]
                                elif len(u_data.shape) == 2:  # 2D data
                                    point_val = u_data[min_idx[0], min_idx[1]]
                                    data = np.full(n_times, point_val) if np.isscalar(point_val) else point_val
                                else:
                                    data = u_data
                            else:
                                data = np.zeros(n_times)

                        elif plot_type == "velocity_v":
                            v_var = self._find_variable(ds_subset, ['v', 'vomecrty', 'vo'])
                            if v_var:
                                v_data = ds_subset[v_var].values
                                if len(v_data.shape) > 2:  # 3D data
                                    data = v_data[:, min_idx[0], min_idx[1]]
                                elif len(v_data.shape) == 2:  # 2D data
                                    point_val = v_data[min_idx[0], min_idx[1]]
                                    data = np.full(n_times, point_val) if np.isscalar(point_val) else point_val
                                else:
                                    data = v_data
                            else:
                                data = np.zeros(n_times)

                        else:
                            # Find appropriate variable
                            var_name = self._find_variable(ds_subset, var_names)
                            if var_name:
                                var_data = ds_subset[var_name].values
                                if len(var_data.shape) > 2:  # 3D data
                                    data = var_data[:, min_idx[0], min_idx[1]]
                                elif len(var_data.shape) == 2:  # 2D data
                                    point_val = var_data[min_idx[0], min_idx[1]]
                                    data = np.full(n_times, point_val) if np.isscalar(point_val) else point_val
                                else:
                                    data = var_data
                            else:
                                data = np.zeros(n_times)

                        time_series_data.append(data)

                    except Exception as e:
                        logger.warning(f"Error processing point ({lon}, {lat}): {e}")
                        time_series_data.append(np.zeros(n_times))

                return time_series_data

        except Exception as e:
            logger.error(f"Error computing ocean boundary input time series: {e}")
            return [np.zeros(int(time_hours * 2)) for _ in sample_points]

    def _compute_tidal_timeseries_from_harmonics(
        self,
        ds: xr.Dataset,
        sample_points: List[Tuple[float, float]],
        plot_type: str,
        time_hours: float
    ) -> List[np.ndarray]:
        """
        Generate time series from TPXO harmonic constants.

        Parameters
        ----------
        ds : xr.Dataset
            TPXO dataset with harmonic constants
        sample_points : List[Tuple[float, float]]
            Sample point coordinates
        plot_type : str
            Type of variable to plot
        time_hours : float
            Duration in hours

        Returns
        -------
        List[np.ndarray]
            Time series data for each sample point
        """
        try:
            # Get coordinates
            lons = ds['lon_z'].values
            lats = ds['lat_z'].values

            # Get constituent names
            constituents = ds['con'].values
            constituent_names = [''.join(c.decode('utf-8') if isinstance(c, bytes) else str(c) for c in const).strip()
                               for const in constituents]

            # Create time array (30-minute intervals)
            dt = 0.5  # hours
            n_times = int(time_hours / dt)
            times = np.arange(0, time_hours, dt)

            time_series_data = []

            for lon, lat in sample_points:
                try:
                    # Find nearest point
                    dist = np.sqrt((lons - lon)**2 + (lats - lat)**2)
                    min_idx = np.unravel_index(np.argmin(dist), dist.shape)

                    # Initialize time series
                    if plot_type == "elevation":
                        # Use elevation harmonic constants
                        amp_data = ds['ha'].values
                        phase_data = ds['hp'].values
                    elif plot_type in ["velocity_u", "velocity_v", "velocity_magnitude"]:
                        # Use velocity harmonic constants (if available)
                        if 'uRe' in ds.data_vars and 'uIm' in ds.data_vars:
                            # Convert complex velocity to amplitude/phase
                            u_re = ds['uRe'].values
                            u_im = ds['uIm'].values
                            v_re = ds['vRe'].values if 'vRe' in ds.data_vars else u_re
                            v_im = ds['vIm'].values if 'vIm' in ds.data_vars else u_im

                            if plot_type == "velocity_u":
                                amp_data = np.sqrt(u_re**2 + u_im**2)
                                phase_data = np.arctan2(u_im, u_re) * 180 / np.pi
                            elif plot_type == "velocity_v":
                                amp_data = np.sqrt(v_re**2 + v_im**2)
                                phase_data = np.arctan2(v_im, v_re) * 180 / np.pi
                            else:  # velocity_magnitude
                                amp_data = np.sqrt((u_re**2 + u_im**2) + (v_re**2 + v_im**2))
                                phase_data = np.zeros_like(amp_data)
                        else:
                            # Fallback to elevation data
                            amp_data = ds['ha'].values
                            phase_data = ds['hp'].values
                    else:
                        # Default to elevation
                        amp_data = ds['ha'].values
                        phase_data = ds['hp'].values

                    # Generate time series from harmonic constants
                    timeseries = np.zeros(len(times))

                    # Standard tidal frequencies (cycles per hour)
                    tidal_frequencies = {
                        'M2': 1.40519e-4 * 3600,  # M2 frequency in cycles/hour
                        'S2': 1.45444e-4 * 3600,  # S2 frequency
                        'N2': 1.37880e-4 * 3600,  # N2 frequency
                        'K1': 0.72921e-4 * 3600,  # K1 frequency
                        'O1': 0.67598e-4 * 3600,  # O1 frequency
                    }

                    for i, const_name in enumerate(constituent_names):
                        const_name_clean = const_name.upper().strip()
                        if const_name_clean in tidal_frequencies:
                            freq = tidal_frequencies[const_name_clean]
                            amp = amp_data[i, min_idx[0], min_idx[1]]
                            phase = phase_data[i, min_idx[0], min_idx[1]]

                            # Skip if amplitude is zero or NaN
                            if np.isnan(amp) or amp == 0:
                                continue

                            # Generate harmonic component
                            timeseries += amp * np.cos(2 * np.pi * freq * times - np.radians(phase))

                    time_series_data.append(timeseries)

                except Exception as e:
                    logger.warning(f"Error processing TPXO point ({lon}, {lat}): {e}")
                    time_series_data.append(np.zeros(len(times)))

            return time_series_data

        except Exception as e:
            logger.error(f"Error computing tidal time series from harmonics: {e}")
            return [np.zeros(int(time_hours * 2)) for _ in sample_points]

    def _compute_processed_boundary_timeseries(
        self,
        boundary_file: Path,
        sample_points: List[Tuple[float, float]],
        plot_type: str,
        time_hours: float
    ) -> List[np.ndarray]:
        """
        Compute ocean boundary time series from processed SCHISM boundary file.

        Parameters
        ----------
        boundary_file : Path
            Path to SCHISM boundary file
        sample_points : List[Tuple[float, float]]
            Sample point coordinates
        plot_type : str
            Type of variable to plot
        time_hours : float
            Duration in hours

        Returns
        -------
        List[np.ndarray]
            Time series data for each sample point
        """
        try:
            import xarray as xr

            # Load boundary file
            ds = xr.open_dataset(boundary_file)

            # Get time subset
            n_times = min(int(time_hours * 2), len(ds.time))
            ds_subset = ds.isel(time=slice(0, n_times))

            # Extract time series data
            if 'time_series' in ds_subset.data_vars:
                time_series = ds_subset['time_series'].values

                # Handle different dimensions
                if len(time_series.shape) == 4:  # (time, nodes, levels, components)
                    n_points = min(len(sample_points), time_series.shape[1])

                    if plot_type == "velocity_magnitude" and time_series.shape[3] >= 2:
                        # Calculate magnitude from u and v components
                        u_data = time_series[:n_times, :n_points, 0, 0]  # Surface u
                        v_data = time_series[:n_times, :n_points, 0, 1]  # Surface v
                        magnitude_data = np.sqrt(u_data**2 + v_data**2)
                        return [magnitude_data[:, i] for i in range(n_points)]

                    elif plot_type == "velocity_u" and time_series.shape[3] >= 1:
                        u_data = time_series[:n_times, :n_points, 0, 0]  # Surface u
                        return [u_data[:, i] for i in range(n_points)]

                    elif plot_type == "velocity_v" and time_series.shape[3] >= 2:
                        v_data = time_series[:n_times, :n_points, 0, 1]  # Surface v
                        return [v_data[:, i] for i in range(n_points)]

                    else:
                        # Default to first component, surface level
                        data = time_series[:n_times, :n_points, 0, 0]
                        return [data[:, i] for i in range(n_points)]

                elif len(time_series.shape) == 3:  # (time, nodes, levels) or (time, nodes, components)
                    n_points = min(len(sample_points), time_series.shape[1])
                    data = time_series[:n_times, :n_points, 0]  # First level/component
                    return [data[:, i] for i in range(n_points)]

                else:  # 2D case (time, nodes)
                    n_points = min(len(sample_points), time_series.shape[1])
                    return [time_series[:n_times, i] for i in range(n_points)]

            else:
                # Fallback: create zero data
                return [np.zeros(n_times) for _ in sample_points]

        except Exception as e:
            logger.error(f"Error computing processed boundary time series: {e}")
            return [np.zeros(int(time_hours * 2)) for _ in sample_points]

    def _get_ocean_variable_names(self, plot_type: str) -> List[str]:
        """Get possible variable names for ocean boundary data."""
        variable_mapping = {
            "elevation": ["ssh", "zos", "sea_surface_height", "elevation"],
            "velocity_u": ["u", "vozocrtx", "uo", "eastward_sea_water_velocity"],
            "velocity_v": ["v", "vomecrty", "vo", "northward_sea_water_velocity"],
            "velocity_magnitude": ["u", "v", "vozocrtx", "vomecrty", "uo", "vo"],
            "temperature": ["temperature", "thetao", "votemper", "sea_water_potential_temperature"],
            "salinity": ["salinity", "so", "vosaline", "sea_water_salinity"]
        }
        return variable_mapping.get(plot_type, [plot_type])

    def _get_ocean_boundary_ylabel(self, plot_type: str) -> str:
        """Get appropriate y-axis label for ocean boundary plot type."""
        ylabel_map = {
            "elevation": "Sea Surface Height (m)",
            "velocity_u": "U Velocity (m/s)",
            "velocity_v": "V Velocity (m/s)",
            "velocity_magnitude": "Velocity Magnitude (m/s)",
            "temperature": "Temperature (°C)",
            "salinity": "Salinity (PSU)"
        }
        return ylabel_map.get(plot_type, plot_type.replace('_', ' ').title())

    def _compute_standardized_time_axis(self, time_hours: float, dt: float = 0.5) -> np.ndarray:
        """
        Compute standardized time axis for consistent comparison plots.

        This ensures that both input and processed data plots use the same
        time axis, making comparison plots properly aligned.

        Parameters
        ----------
        time_hours : float
            Duration in hours for the time series
        dt : float, optional
            Time step in hours. Default is 0.5 (30 minutes)

        Returns
        -------
        np.ndarray
            Standardized time array in hours
        """
        # Reason: Create consistent time axis regardless of data length variations
        return np.arange(0, time_hours + dt/2, dt)

    def _align_data_to_time_axis(self, data: np.ndarray, current_times: np.ndarray,
                                 target_times: np.ndarray) -> np.ndarray:
        """
        Align data array to match target time axis through interpolation.

        Parameters
        ----------
        data : np.ndarray
            Input data array
        current_times : np.ndarray
            Current time array corresponding to data
        target_times : np.ndarray
            Target time array to align data to

        Returns
        -------
        np.ndarray
            Data aligned to target time axis
        """
        from scipy import interpolate

        # Reason: Handle cases where data and time arrays have different lengths
        if len(data) != len(current_times):
            # Truncate to minimum length to avoid indexing errors
            min_len = min(len(data), len(current_times))
            data = data[:min_len]
            current_times = current_times[:min_len]

        if len(current_times) == 0 or len(data) == 0:
            # Return zeros array matching target times if no data
            return np.zeros_like(target_times)

        # Interpolate data to target time axis
        try:
            f = interpolate.interp1d(current_times, data, kind='linear',
                                   bounds_error=False, fill_value=(data[0], data[-1]))
            return f(target_times)
        except Exception:
            # Fallback: pad or truncate to match target length
            if len(data) < len(target_times):
                # Pad with last value
                padded = np.full(len(target_times), data[-1] if len(data) > 0 else 0)
                padded[:len(data)] = data
                return padded
            else:
                # Truncate to target length
                return data[:len(target_times)]
